{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#voxelmorph","title":"voxelmorph","text":"<p>Deep learning tools for deformable medical image registration. This package offers reference implementations of core registration networks, loss functions, and utilities, with PyTorch and TensorFlow backends.</p>"},{"location":"#voxelmorph--subpackages","title":"Subpackages","text":"MODULE DESCRIPTION <code>nn</code> <p>Torch-based neural network components for VoxelMorph.</p> <code>py</code> <p>Python utilities for VoxelMorph.</p> <code>???+ quote \"Citation\"</code> APABibTeX <p>Balakrishnan, G., Zhao, A., Sabuncu, M. R., Guttag, J., &amp; Dalca, A. V. (2018). VoxelMorph: A Learning Framework for Deformable Medical Image Registration. arXiv:1809.05231. https://arxiv.org/abs/1809.05231</p> <pre><code>@article{balakrishnan2018voxelmorph,\n  title   = {VoxelMorph: A Learning Framework for Deformable Medical\n             Image Registration},\n  author  = {Balakrishnan, Guha and Zhao, Amy and Sabuncu, Mert R and\n             Guttag, John and Dalca, Adrian V},\n  journal = {arXiv preprint arXiv:1809.05231},\n  year    = {2018},\n  url     = {https://arxiv.org/abs/1809.05231}\n}\n</code></pre>"},{"location":"api/nn/functional/","title":"nn.functional","text":""},{"location":"api/nn/functional/#voxelmorph.nn.functional","title":"voxelmorph.nn.functional","text":"<p>Functions containing the core operations and logic of for image registration for <code>voxelmorph</code> written in PyTorch.</p>"},{"location":"api/nn/functional/#voxelmorph.nn.functional.affine_to_disp","title":"affine_to_disp","text":"<pre><code>affine_to_disp(affine: Tensor, meshgrid: Tensor, rotate_around_center: Optional[bool] = True) -&gt; Tensor\n</code></pre> <p>Convert an affine transformation matrix to a displacement field.</p> PARAMETER DESCRIPTION <code>affine</code> <p>Affine transformation matrix. It is expected to be a vox2vox target to source transformation.</p> <p> TYPE: <code>Tensor</code> </p> <code>meshgrid</code> <p>The meshgrid tensor of shape <code>(W, H[, D], N)</code>, where N is the spatial dimensionality.</p> <p> TYPE: <code>Tensor</code> </p> <code>rotate_around_center</code> <p>If True, the rotation will be around the center of the image, otherwise around the origin.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>The generated displacement field of shape <code>meshgrid.shape[:-1]</code>.</p> Source code in <code>voxelmorph/nn/functional.py</code> <pre><code>def affine_to_disp(\n    affine: Tensor,\n    meshgrid: Tensor,\n    rotate_around_center: Optional[bool] = True\n) -&gt; Tensor:\n    \"\"\"\n    Convert an affine transformation matrix to a displacement field.\n\n    Parameters\n    ----------\n    affine : Tensor\n        Affine transformation matrix. It is expected to be a vox2vox target to source\n        transformation.\n    meshgrid : Tensor\n        The meshgrid tensor of shape `(W, H[, D], N)`, where N is the spatial dimensionality.\n    rotate_around_center : bool, optional\n        If True, the rotation will be around the center of the image, otherwise around the origin.\n\n    Returns\n    -------\n    Tensor\n        The generated displacement field of shape `meshgrid.shape[:-1]`.\n    \"\"\"\n    ndim = meshgrid.shape[-1]\n    shape = meshgrid.shape[:-1]\n\n    # if rotate_around_center is enabled, adjust the meshgrid so that the rotation\n    # is around the center of the image instead of the origin\n    grid = meshgrid.clone() if rotate_around_center else meshgrid\n    if rotate_around_center:\n        for d in range(ndim):\n            grid[..., d] -= (shape[d] - 1) / 2\n\n    # convert the meshgrid to homogeneous coordinates by appending a column of ones\n    coords = grid.view(-1, ndim)\n    ones = torch.ones((coords.shape[-2], 1), device=meshgrid.device)\n    coords = torch.cat([coords, ones], dim=-1)\n\n    # Apply the affine transformation to the coordinates to get the displacement field\n    # affine needs to be vox2vox transformation matrix, and mapping from target to source\n    # the computed displacement field is the absolute crs in source space\n    disp = (affine @ coords.T)[:ndim].T\n\n    # Reshape the displacement field to match the shape of the meshgrid and subtract\n    # the original meshgrid to get the displacement field\n    disp = disp.view(*shape, ndim) - grid\n\n    return disp\n</code></pre>"},{"location":"api/nn/functional/#voxelmorph.nn.functional.angles_to_rotation_matrix","title":"angles_to_rotation_matrix","text":"<pre><code>angles_to_rotation_matrix(rotation: Tensor, degrees: bool = True) -&gt; Tensor\n</code></pre> <p>Compute a rotation matrix from the given rotation angles.</p> PARAMETER DESCRIPTION <code>rotation</code> <p>A tensor containing the rotation angles. If <code>degrees</code> is True, the angles are in degrees, otherwise they are in radians.</p> <p> TYPE: <code>Tensor</code> </p> <code>degrees</code> <p>Whether to interpret the rotation angles as degrees.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>The computed <code>(ndim + 1, ndim + 1)</code> rotation matrix.</p> Source code in <code>voxelmorph/nn/functional.py</code> <pre><code>def angles_to_rotation_matrix(\n    rotation: Tensor,\n    degrees: bool = True\n) -&gt; Tensor:\n    \"\"\"\n    Compute a rotation matrix from the given rotation angles.\n\n    Parameters\n    ----------\n    rotation : Tensor\n        A tensor containing the rotation angles. If `degrees` is True, the angles\n        are in degrees, otherwise they are in radians.\n    degrees : bool, optional\n        Whether to interpret the rotation angles as degrees.\n\n    Returns\n    -------\n    Tensor\n        The computed `(ndim + 1, ndim + 1)` rotation matrix.\n    \"\"\"\n    if degrees:\n        rotation = torch.deg2rad(rotation)\n\n    # scalar value allowed for 2D transforms\n    rotation = torch.as_tensor(rotation)\n    if rotation.ndim == 0:\n        rotation = rotation.view(1)\n    num_angles = len(rotation)\n\n    # build the matrix\n    if num_angles == 1:\n        c, s = torch.cos(rotation[0]), torch.sin(rotation[0])\n        matrix = torch.tensor([[c, -s], [s, c]], dtype=torch.float64)\n    elif num_angles == 3:\n        c, s = torch.cos(rotation[0]), torch.sin(rotation[0])\n        rx = torch.tensor([[1, 0, 0], [0, c, s], [0, -s, c]], dtype=torch.float64)\n        c, s = torch.cos(rotation[1]), torch.sin(rotation[1])\n        ry = torch.tensor([[c, 0, s], [0, 1, 0], [-s, 0, c]], dtype=torch.float64)\n        c, s = torch.cos(rotation[2]), torch.sin(rotation[2])\n        rz = torch.tensor([[c, s, 0], [-s, c, 0], [0, 0, 1]], dtype=torch.float64)\n        matrix = rx @ ry @ rz\n    else:\n        raise ValueError(f'expected 1 (2D) or 3 (3D) rotation angles, got {num_angles}')\n\n    return matrix.to(rotation.device)\n</code></pre>"},{"location":"api/nn/functional/#voxelmorph.nn.functional.chance","title":"chance","text":"<pre><code>chance(prob: float) -&gt; bool\n</code></pre> <p>Returns True with given probability.</p> PARAMETER DESCRIPTION <code>prob</code> <p>Probability of returning True. Must be in the range [0, 1].</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True with probability <code>prob</code>.</p> Source code in <code>voxelmorph/nn/functional.py</code> <pre><code>def chance(prob: float) -&gt; bool:\n    \"\"\"\n    Returns True with given probability.\n\n    Parameters\n    ----------\n    prob : float\n        Probability of returning True. Must be in the range [0, 1].\n\n    Returns\n    -------\n    bool\n        True with probability `prob`.\n    \"\"\"\n    if prob &lt; 0.0 or prob &gt; 1.0:\n        raise ValueError(f'chance() expected a value in the range [0, 1], but got {prob}')\n    return frandom.rand() &lt; prob\n</code></pre>"},{"location":"api/nn/functional/#voxelmorph.nn.functional.compose_affine","title":"compose_affine","text":"<pre><code>compose_affine(ndim: int, translation: Tensor = None, rotation: Tensor = None, scale: Tensor = None, shear: Tensor = None, degrees: bool = True, device: device = None) -&gt; Tensor\n</code></pre> <p>Composes an affine matrix from a set of translation, rotation, scale, and shear transform components.</p> PARAMETER DESCRIPTION <code>ndim</code> <p>The number of dimensions of the affine matrix. Must be 2 or 3.</p> <p> TYPE: <code>int</code> </p> <code>translation</code> <p>The translation vector. Must be a vector of size <code>ndim</code>.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>rotation</code> <p>The rotation angles. Must be a scalar value for 2D affine matrices, and a tensor of size 3 for 3D affine matrices.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>scale</code> <p>The scaling factor. Can be scalar or vector of size <code>ndim</code>.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>shear</code> <p>The shearing factor. Must be a scalar value for 2D affine matrices, and a tensor of size 3 for 3D affine matrices.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>degrees</code> <p>Whether to interpret the rotation angles as degrees.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>device</code> <p>The device of the returned matrix.</p> <p> TYPE: <code>device</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>The composed affine matrix, as a tensor of shape <code>(ndim + 1, ndim + 1)</code>.</p> Source code in <code>voxelmorph/nn/functional.py</code> <pre><code>def compose_affine(\n    ndim: int,\n    translation: Tensor = None,\n    rotation: Tensor = None,\n    scale: Tensor = None,\n    shear: Tensor = None,\n    degrees: bool = True,\n    device: torch.device = None\n) -&gt; Tensor:\n    \"\"\"\n    Composes an affine matrix from a set of translation, rotation, scale,\n    and shear transform components.\n\n    Parameters\n    ----------\n    ndim (int):\n        The number of dimensions of the affine matrix. Must be 2 or 3.\n    translation : Tensor, optional\n        The translation vector. Must be a vector of size `ndim`. \n    rotation : Tensor, optional\n        The rotation angles. Must be a scalar value for 2D affine matrices,\n        and a tensor of size 3 for 3D affine matrices.\n    scale : Tensor, optional\n        The scaling factor. Can be scalar or vector of size `ndim`.\n    shear : Tensor, optional\n        The shearing factor. Must be a scalar value for 2D affine matrices,\n        and a tensor of size 3 for 3D affine matrices.\n    degrees : bool, optional\n        Whether to interpret the rotation angles as degrees.\n    device : torch.device, optional\n        The device of the returned matrix.\n\n    Returns\n    -------\n    Tensor\n        The composed affine matrix, as a tensor of shape `(ndim + 1, ndim + 1)`.\n    \"\"\"\n    if ndim not in (2, 3):\n        raise ValueError(f'affine transform must be 2D or 3D, got ndim {ndim}')\n\n    # check translation\n    translation = torch.zeros(ndim) if translation is None else torch.as_tensor(translation)\n    if len(translation) != ndim:\n        raise ValueError(f'translation must be of shape ({ndim},)')\n\n    # check rotation angles\n    expected = 3 if ndim == 3 else 1\n    rotation = torch.zeros(expected) if rotation is None else torch.as_tensor(rotation)\n    if rotation.ndim == 0 and ndim == 3 or rotation.ndim != 0 and rotation.shape[0] != expected:\n        raise ValueError(f'rotation must be of shape ({expected},)')\n\n    # check scaling factor\n    scale = torch.ones(ndim) if scale is None else torch.as_tensor(scale)\n    if scale.ndim == 0:\n        scale = scale.repeat(ndim)\n    if scale.shape[0] != ndim:\n        raise ValueError(f'scale must be of size {ndim}')\n\n    # check shearing\n    expected = 3 if ndim == 3 else 1\n    shear = torch.zeros(expected) if shear is None else torch.as_tensor(shear)\n    if shear.ndim == 0:\n        shear = shear.view(1)\n    if shear.shape[0] != expected:\n        raise ValueError(f'shear must be of shape ({expected},)')\n\n    # start from translation\n    T = torch.eye(ndim + 1, dtype=torch.float64)\n    T[:ndim, -1] = translation\n\n    # rotation matrix\n    R = torch.eye(ndim + 1, dtype=torch.float64)\n    R[:ndim, :ndim] = angles_to_rotation_matrix(rotation, degrees=degrees)\n\n    # scaling\n    Z = torch.diag(torch.cat([scale, torch.ones(1, dtype=torch.float64)]))\n\n    # shear matrix\n    S = torch.eye(ndim + 1, dtype=torch.float64)\n    S[0][1] = shear[0]\n    if ndim == 3:\n        S[0][2] = shear[1]\n        S[1][2] = shear[2]\n\n    # compose component matrices\n    matrix = T @ R @ Z @ S\n\n    return torch.as_tensor(matrix, dtype=torch.float32, device=device)\n</code></pre>"},{"location":"api/nn/functional/#voxelmorph.nn.functional.coords_to_disp","title":"coords_to_disp","text":"<pre><code>coords_to_disp(coords, meshgrid=None) -&gt; Tensor\n</code></pre> <p>TODOC</p> Source code in <code>voxelmorph/nn/functional.py</code> <pre><code>def coords_to_disp(coords, meshgrid=None) -&gt; Tensor:\n    \"\"\"\n    TODOC\n    \"\"\"\n    if meshgrid is None:\n        meshgrid = grid_coordinates(coords.shape[:-1], device=coords.device)\n\n    raise NotImplementedError(\n        'coords_to_disp is not yet implemented. '\n        'contact andrew if you get this... or implement it :)'\n    )\n</code></pre>"},{"location":"api/nn/functional/#voxelmorph.nn.functional.disp_to_coords","title":"disp_to_coords","text":"<pre><code>disp_to_coords(disp, meshgrid=None) -&gt; Tensor\n</code></pre> <p>Convert the displacement crs to absolute crs scaled to range [-1, 1].</p> Parameters: <p>disp: torch.Tensor     Displacement crs field meshgrid: torch.Tensor, optional    crs grid for the image shape</p> Returns: <p>torch.Tensor:     The absolute crs field scaled to range [-1, 1].</p> Source code in <code>voxelmorph/nn/functional.py</code> <pre><code>def disp_to_coords(disp, meshgrid=None) -&gt; Tensor:\n    \"\"\"\n    Convert the displacement crs to absolute crs scaled to range [-1, 1].\n\n    Parameters:\n    -----------\n    disp: torch.Tensor\n        Displacement crs field\n    meshgrid: torch.Tensor, optional\n       crs grid for the image shape\n\n    Returns:\n    --------\n    torch.Tensor:\n        The absolute crs field scaled to range [-1, 1].\n    \"\"\"\n    if meshgrid is None:\n        meshgrid = grid_coordinates(disp.shape[:-1], device=disp.device)\n\n    shape = disp.shape[:-1]\n    ndim = disp.shape[-1]\n\n    # compute the absolute crs field\n    # scale the field to range [-1, 1], which is expected by torch.nn.functional.grid_sample()\n    coords = (meshgrid + disp)\n    for d in range(ndim):\n        if shape[d] == 1:\n            coords[..., d] *= 0\n        else:\n            coords[..., d] *= 2 / (shape[d] - 1)\n            coords[..., d] -= 1\n\n    coords = coords.flip(-1)\n\n    return coords\n</code></pre>"},{"location":"api/nn/functional/#voxelmorph.nn.functional.gaussian_blur","title":"gaussian_blur","text":"<pre><code>gaussian_blur(image: Tensor, sigma: List[float], batched: bool = False, truncate: int = 3) -&gt; Tensor\n</code></pre> <p>Apply Gaussian blurring to an image.</p> PARAMETER DESCRIPTION <code>image</code> <p>An input tensor of shape <code>(C, W, H[, D])</code> to blur. A batch dimension can be included by setting <code>batched</code> to <code>True</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>sigma</code> <p>Standard deviation(s) of the Gaussian filter along each dimension.</p> <p> TYPE: <code>float or List[float]</code> </p> <code>batched</code> <p>Whether the input tensor includes a batch dimension.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>truncate</code> <p>The number of standard deviations to extend the kernel before truncating.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>The blurred tensor with the same shape as the input tensor.</p> Notes <p>The Gaussian filter is applied using convolution. The size of the filter kernel is determined by the standard deviation and the truncation factor.</p> Source code in <code>voxelmorph/nn/functional.py</code> <pre><code>def gaussian_blur(\n    image: Tensor,\n    sigma: List[float],\n    batched: bool = False,\n    truncate: int = 3,\n) -&gt; Tensor:\n    \"\"\"\n    Apply Gaussian blurring to an image.\n\n    Parameters\n    ----------\n    image : Tensor\n        An input tensor of shape `(C, W, H[, D])` to blur. A batch dimension\n        can be included by setting `batched` to `True`.\n    sigma : float or List[float]\n        Standard deviation(s) of the Gaussian filter along each dimension.\n    batched : bool, optional\n        Whether the input tensor includes a batch dimension.\n    truncate : int, optional\n        The number of standard deviations to extend the kernel before truncating.\n\n    Returns\n    -------\n    Tensor\n        The blurred tensor with the same shape as the input tensor.\n\n    Notes\n    -----\n    The Gaussian filter is applied using convolution. The size of the filter kernel is\n    determined by the standard deviation and the truncation factor.\n    \"\"\"\n    ndim = image.ndim - (2 if batched else 1)\n\n    # sanity check for common mistake\n    if ndim == 4 and not batched:\n        raise ValueError(\n            f'gaussian blur input has {image.ndim} dims, but batched option is False'\n        )\n\n    # normalize sigmas\n    if torch.as_tensor(sigma).ndim == 0:\n        sigma = [sigma] * ndim\n    if len(sigma) != ndim:\n        raise ValueError(f'sigma must be {ndim}D, but got length {len(sigma)}')\n\n    blurred = image if batched else image.unsqueeze(0)\n\n    if all(s == sigma[0] for s in sigma):\n        # Isotropic, can use the same vector in all directions cases. Since\n        # creating the kernel is actually one of the most time intensive steps\n        # this is an efficiency gain worth exploiting\n        kernel_vec = gaussian_kernel_1d(\n            sigma[0],\n            truncate,\n            device=blurred.device,\n            dtype=blurred.dtype,\n        )\n        kernel_vecs = [kernel_vec] * ndim\n    else:\n        # Three different kernels, one for each direction\n        kernel_vecs = [\n            gaussian_kernel_1d(\n                s,\n                truncate,\n                device=blurred.device,\n                dtype=blurred.dtype,\n            )\n            for s in sigma\n        ]\n\n    for dim, kernel in enumerate(kernel_vecs):\n\n        # apply the convolution\n        slices = [None] * (ndim + 2)\n        slices[dim + 2] = slice(None)\n        kernel_dim = kernel[slices]\n        conv = getattr(torch.nn.functional, f'conv{ndim}d')\n        blurred = conv(blurred, kernel_dim, groups=image.shape[0], padding=\"same\")\n\n    if not batched:\n        blurred = blurred.squeeze(0)\n\n    return blurred\n</code></pre>"},{"location":"api/nn/functional/#voxelmorph.nn.functional.gaussian_kernel_1d","title":"gaussian_kernel_1d","text":"<pre><code>gaussian_kernel_1d(sigma, truncate: int = 3, device=None, dtype=None)\n</code></pre> <p>Generate a 1D Gaussian kernel with the specified standard deviations.</p> PARAMETER DESCRIPTION <code>sigma</code> <p>A list of standard deviations for each dimension.</p> <p> TYPE: <code>float</code> </p> <code>truncate</code> <p>The number of standard deviations to extend the kernel before truncating.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> <code>device</code> <p>The device on which to create the kernel.</p> <p> TYPE: <code>device</code> DEFAULT: <code>None</code> </p> <code>dtype</code> <p>Data type of the returned kernel.</p> <p> TYPE: <code>dtype | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A kernel of shape <code>2 * truncate * sigma + 1</code>.</p> Notes <p>The kernel is truncated when its values drop below <code>1e-5</code> of the maximum value.</p> Source code in <code>voxelmorph/nn/functional.py</code> <pre><code>def gaussian_kernel_1d(sigma, truncate: int = 3, device=None, dtype=None):\n    \"\"\"\n    Generate a 1D Gaussian kernel with the specified standard deviations.\n\n    Parameters\n    ----------\n    sigma : float\n        A list of standard deviations for each dimension.\n    truncate : int, optional\n        The number of standard deviations to extend the kernel before truncating.\n    device : torch.device, optional\n        The device on which to create the kernel.\n    dtype : torch.dtype | None, optional\n        Data type of the returned kernel.\n\n    Returns\n    -------\n    Tensor\n        A kernel of shape `2 * truncate * sigma + 1`.\n\n    Notes\n    -----\n    The kernel is truncated when its values drop below `1e-5` of the maximum value.\n    \"\"\"\n    r = int(truncate * sigma + 0.5)\n    x = torch.arange(-r, r + 1, device=device, dtype=dtype)\n    sigma2 = 1 / torch.clip(torch.as_tensor(sigma), min=1e-5).pow(2)\n    pdf = torch.exp(-0.5 * (x.pow(2) * sigma2))\n    return pdf / pdf.sum()\n</code></pre>"},{"location":"api/nn/functional/#voxelmorph.nn.functional.grid_coordinates","title":"grid_coordinates","text":"<pre><code>grid_coordinates(shape: Sequence[int], indexing: Optional[Literal['ij', 'xy']] = 'ij', dtype: Optional[dtype] = torch.float32, device: Optional[device] = None) -&gt; Tensor\n</code></pre> <p>Generates a grid of coordinates with the specified spatial shape.</p> PARAMETER DESCRIPTION <code>shape</code> <p>The spatial shape of the grid to generate.</p> <p> TYPE: <code>tuple of int</code> </p> <code>indexing</code> <p>The indexing convention to use. 'ij' for matrix indexing, 'xy' for Cartesian indexing. Default is 'ij'.</p> <p> TYPE: <code>(ij, xy)</code> DEFAULT: <code>'ij'</code> </p> <code>dtype</code> <p>The desired data type of the output tensor. Default is torch.float32.</p> <p> TYPE: <code>dtype</code> DEFAULT: <code>float32</code> </p> <code>device</code> <p>The device on which to create the tensor. Default is None, which uses the current device.</p> <p> TYPE: <code>device</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A tensor of shape (*shape, len(shape)) containing the grid coordinates.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; grid_coordinates((2, 3))\ntensor([[[0., 0.],\n         [0., 1.],\n         [0., 2.]],\n        [[1., 0.],\n         [1., 1.],\n         [1., 2.]]])\n&gt;&gt;&gt; grid_coordinates((1, 2, 2), device=torch.device('cuda:0'))\ntensor([[[[0., 0., 0.],\n           [0., 0., 1.]],\n          [[0., 1., 0.],\n           [0., 1., 1.]]]], device='cuda:0')\n</code></pre> Source code in <code>voxelmorph/nn/functional.py</code> <pre><code>def grid_coordinates(\n    shape: Sequence[int],\n    indexing: Optional[Literal['ij', 'xy']] = 'ij',\n    dtype: Optional[torch.dtype] = torch.float32,\n    device: Optional[torch.device] = None\n) -&gt; Tensor:\n    \"\"\"\n    Generates a grid of coordinates with the specified spatial shape.\n\n    Parameters\n    ----------\n    shape : tuple of int\n        The spatial shape of the grid to generate.\n    indexing : {'ij', 'xy'}, optional\n        The indexing convention to use. 'ij' for matrix indexing, 'xy' for Cartesian\n        indexing. Default is 'ij'.\n    dtype : torch.dtype, optional\n        The desired data type of the output tensor. Default is torch.float32.\n    device : torch.device, optional\n        The device on which to create the tensor. Default is None, which uses the\n        current device.\n\n    Returns\n    -------\n    torch.Tensor\n        A tensor of shape (*shape, len(shape)) containing the grid coordinates.\n\n    Examples\n    --------\n    &gt;&gt;&gt; grid_coordinates((2, 3))\n    tensor([[[0., 0.],\n             [0., 1.],\n             [0., 2.]],\n            [[1., 0.],\n             [1., 1.],\n             [1., 2.]]])\n    &gt;&gt;&gt; grid_coordinates((1, 2, 2), device=torch.device('cuda:0'))\n    tensor([[[[0., 0., 0.],\n               [0., 0., 1.]],\n              [[0., 1., 0.],\n               [0., 1., 1.]]]], device='cuda:0')\n    \"\"\"\n    ranges = [torch.arange(s, dtype=dtype, device=device) for s in shape]\n    meshgrid = torch.stack(torch.meshgrid(*ranges, indexing=indexing), dim=-1)\n    return meshgrid\n</code></pre>"},{"location":"api/nn/functional/#voxelmorph.nn.functional.integrate_disp","title":"integrate_disp","text":"<pre><code>integrate_disp(disp: Tensor, steps: int, meshgrid: Tensor = None) -&gt; Tensor\n</code></pre> <p>TODOC</p> Source code in <code>voxelmorph/nn/functional.py</code> <pre><code>def integrate_disp(\n    disp: Tensor,\n    steps: int,\n    meshgrid: Tensor = None\n) -&gt; Tensor:\n    \"\"\"\n    TODOC\n    \"\"\"\n    if meshgrid is None:\n        # generate a crs grid\n        meshgrid = grid_coordinates(disp.shape[:-1], device=disp.device)\n\n    if steps == 0:\n        return disp\n\n    disp = disp / (2 ** steps)\n    for _ in range(steps):\n        disp += spatial_transform(disp.movedim(-1, 0), disp, meshgrid=meshgrid).movedim(0, -1)\n\n    return disp\n</code></pre>"},{"location":"api/nn/functional/#voxelmorph.nn.functional.perlin","title":"perlin","text":"<pre><code>perlin(shape, smoothing: Union[float, List[float]] = None, magnitude: Union[float, List[float]] = 1.0, weights=None, device=None, method='blur')\n</code></pre> <p>Generates a perlin noise image.</p> PARAMETER DESCRIPTION <code>shape</code> <p>The desired shape of the output tensor. Can be 2D or 3D.</p> <p> TYPE: <code>List[int]</code> </p> <code>smoothing</code> <p>The spatial smoothing sigma(s) in voxel coordinates.</p> <p> TYPE: <code>float or List[float]</code> DEFAULT: <code>None</code> </p> <code>magnitude</code> <p>The standard deviation of the noise.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <code>weights</code> <p>The weights of the smoothing components (scales). If None, defaults to monotonically increasing weights.</p> <p> TYPE: <code>float or List[float]</code> DEFAULT: <code>None</code> </p> <code>device</code> <p>The device on which the output tensor is allocated. If None, defaults to CPU.</p> <p> TYPE: <code>device or None</code> DEFAULT: <code>None</code> </p> <code>method</code> <p>Method for noise generation. Upsampling is much faster and more memory efficient for larger sigma values, but at the cost of quality.</p> <p> TYPE: <code>blur or upsample</code> DEFAULT: <code>'blur'</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A Perlin noise image of shape <code>shape</code>.</p> Source code in <code>voxelmorph/nn/functional.py</code> <pre><code>def perlin(\n    shape,\n    smoothing: Union[float, List[float]] = None,\n    magnitude: Union[float, List[float]] = 1.0,\n    weights=None,\n    device=None,\n    method='blur'\n):\n    \"\"\"\n    Generates a perlin noise image.\n\n    Parameters\n    ----------\n    shape : List[int]\n        The desired shape of the output tensor. Can be 2D or 3D.\n    smoothing : float or List[float]\n        The spatial smoothing sigma(s) in voxel coordinates.\n    magnitude : float\n        The standard deviation of the noise.\n    weights : float or List[float]\n        The weights of the smoothing components (scales). If None, defaults\n        to monotonically increasing weights.\n    device : torch.device or None, optional\n        The device on which the output tensor is allocated. If None, defaults to CPU.\n    method : 'blur' or 'upsample'\n        Method for noise generation. Upsampling is much faster and more memory efficient\n        for larger sigma values, but at the cost of quality.\n\n    Returns\n    -------\n    Tensor\n        A Perlin noise image of shape `shape`.\n    \"\"\"\n    if smoothing is None:\n        smoothing = 2 ** np.arange(np.log2(max(shape)))[1:]\n\n    elif np.isscalar(smoothing):\n        return smooth_gaussian(\n            shape, smoothing, magnitude, device=device, method=method\n        )\n\n    if len(smoothing) == 1:\n        weights = [None]\n\n    elif weights is None:\n        weights = np.arange(len(smoothing)) + 1\n\n    noise = None\n    for s, w in zip(smoothing, weights):\n\n        # generate smooth field\n        sample = smooth_gaussian(shape, s, device=device, method=method)\n        if w is not None:\n            sample *= w\n\n        # merge the noise at this scale with the rest\n        if noise is None:\n            noise = sample\n\n        else:\n            noise += sample\n\n    # in-place normalize\n    noise -= noise.mean()\n    noise *= magnitude / noise.std()\n    return noise\n</code></pre>"},{"location":"api/nn/functional/#voxelmorph.nn.functional.random_affine","title":"random_affine","text":"<pre><code>random_affine(ndim: int, max_translation: float = 0, max_rotation: float = 0, max_scaling: float = 1, device: device = None, sampling: bool = True) -&gt; Tensor\n</code></pre> PARAMETER DESCRIPTION <code>ndim</code> <p>Dimensionality of target transform.</p> <p> TYPE: <code>int</code> </p> <code>max_translation</code> <p>Range to sample translation parameters from. Scalar values define the max deviation from 0.0 (-max_translation, max_translation).</p> <p> TYPE: <code>float</code> DEFAULT: <code>0</code> </p> <code>max_rotation</code> <p>Range to sample rotation parameters from. Scalar values define the max deviation from 0.0 (-max_rotation, max_rotation).</p> <p> TYPE: <code>float</code> DEFAULT: <code>0</code> </p> <code>max_scaling</code> <p>Max to sample scale parameters from. It is converted into a 2-element array defines the (min, max) deviation from 1.0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>vox2vox affine matrix rotating around the image center</p> Source code in <code>voxelmorph/nn/functional.py</code> <pre><code>def random_affine(\n    ndim: int,\n    max_translation: float = 0,\n    max_rotation: float = 0,\n    max_scaling: float = 1,\n    device: torch.device = None,\n    sampling: bool = True\n) -&gt; Tensor:\n    \"\"\"\n    Parameters\n    ----------\n    ndim : int\n        Dimensionality of target transform.\n    max_translation : float\n        Range to sample translation parameters from. Scalar values define the max\n        deviation from 0.0 (-max_translation, max_translation).\n    max_rotation : float\n        Range to sample rotation parameters from. Scalar values define the max\n        deviation from 0.0 (-max_rotation, max_rotation).\n    max_scaling : float\n        Max to sample scale parameters from.\n        It is converted into a 2-element array defines the (min, max) deviation from 1.0.\n\n    Returns\n    -------\n    Tensor\n        vox2vox affine matrix rotating around the image center\n    \"\"\"\n\n    #\n    if (sampling):\n        translation_range = sorted([-max_translation, max_translation])\n        translation = np.random.uniform(*translation_range, size=ndim)\n    else:\n        translation = np.array([max_translation] * ndim)\n\n    #\n    if (sampling):\n        rotation_range = sorted([-max_rotation, max_rotation])\n        rotation = np.random.uniform(*rotation_range, size=(1 if ndim == 2 else 3))\n    else:\n        rotation = np.array([max_rotation] * (1 if ndim == 2 else 3))\n\n    #\n    if (sampling):\n        if max_scaling &lt; 1:\n            raise ValueError('max scaling to random affine cannot be less than 1, '\n                             'see function doc for more info')\n        inv = np.random.choice([-1, 1], size=ndim)\n        scale = np.random.uniform(1, max_scaling, size=ndim) ** inv\n    else:\n        scale = np.array(max_scaling * ndim)\n\n    # compose from random paramters\n    aff = compose_affine(\n        ndim=ndim,\n        translation=translation,\n        rotation=rotation,\n        scale=scale,\n        device=device)\n    return aff\n</code></pre>"},{"location":"api/nn/functional/#voxelmorph.nn.functional.random_disp","title":"random_disp","text":"<pre><code>random_disp(shape: List[int], smoothing: Union[float, List[float]] = 10, magnitude: Union[float, List[float]] = 10, integrations: int = 0, voxsize: float = 1, meshgrid: Tensor = None, device: device = None, perlin_method: str = 'upsample') -&gt; Tensor\n</code></pre> <p>TODOC</p> Source code in <code>voxelmorph/nn/functional.py</code> <pre><code>def random_disp(\n    shape: List[int],\n    smoothing: Union[float, List[float]] = 10,\n    magnitude: Union[float, List[float]] = 10,\n    integrations: int = 0,\n    voxsize: float = 1,\n    meshgrid: Tensor = None,\n    device: torch.device = None,\n    perlin_method: str = 'upsample'\n) -&gt; Tensor:\n    \"\"\"\n    TODOC\n    \"\"\"\n\n    # Perlin can take a list so\n    smoothing = smoothing / voxsize\n    magnitude = magnitude / voxsize\n\n    # randomly sample a displacement crs field of the input shape\n    ndim = len(shape)\n    disp = [\n        perlin(\n            shape, smoothing, magnitude, method=perlin_method, device=device\n        ) for i in range(ndim)\n    ]\n    disp = torch.stack(disp, dim=-1)\n\n    if integrations &gt; 0:\n        disp = integrate_disp(disp, integrations, meshgrid)\n\n    return disp\n</code></pre>"},{"location":"api/nn/functional/#voxelmorph.nn.functional.random_transform","title":"random_transform","text":"<pre><code>random_transform(shape: List[int], affine_probability: float = 1.0, max_translation: float = 5.0, max_rotation: float = 5.0, max_scaling: float = 1.1, warp_probability: float = 1.0, warp_integrations: int = 5, warp_smoothing_range: List[int] = [10, 20], warp_magnitude_range: List[int] = [1, 2], voxsize: int = 1, device: device = None, isdisp: bool = True, perlin_method: str = 'upsample', sampling: bool = True) -&gt; Tensor\n</code></pre> <p>generate a randomly sampled transform</p> Parameters: <p>disp: torch.Tensor     Displacement crs field meshgrid: torch.Tensor, optional    crs grid for the image shape</p> Returns: <p>torch.Tensor:    displacement crs field, or    absolute crs field scaled to range [-1, 1] if isdisp is False</p> Source code in <code>voxelmorph/nn/functional.py</code> <pre><code>def random_transform(\n    shape: List[int],\n    affine_probability: float = 1.0,\n    max_translation: float = 5.0,\n    max_rotation: float = 5.0,\n    max_scaling: float = 1.1,\n    warp_probability: float = 1.0,\n    warp_integrations: int = 5,\n    warp_smoothing_range: List[int] = [10, 20],\n    warp_magnitude_range: List[int] = [1, 2],\n    voxsize: int = 1,\n    device: torch.device = None,\n    isdisp: bool = True,\n    perlin_method: str = 'upsample',\n    sampling: bool = True,\n) -&gt; Tensor:\n    \"\"\"\n    generate a randomly sampled transform\n\n    Parameters:\n    -----------\n    disp: torch.Tensor\n        Displacement crs field\n    meshgrid: torch.Tensor, optional\n       crs grid for the image shape\n\n    Returns:\n    --------\n    torch.Tensor:\n       displacement crs field, or\n       absolute crs field scaled to range [-1, 1] if isdisp is False\n    \"\"\"\n    ndim = len(shape)\n    trf = None\n\n    # generate a random affine\n    if chance(affine_probability):\n\n        # compute meshgrid, it is the target crs\n        meshgrid = grid_coordinates(shape, device=device)\n\n        # convert max_translation from mm to voxel\n        # the matrix returned from random_affine() is vox2vox rotating around the image center.\n        # it is used as target to source transformation in affine_to_disp() to covert\n        # the vox2vox matrix to dispacement field.\n        max_translation = max_translation / voxsize\n        matrix = random_affine(\n            ndim=ndim,\n            max_translation=max_translation,\n            max_rotation=max_rotation,\n            max_scaling=max_scaling,\n            device=device,\n            sampling=sampling)\n        trf = affine_to_disp(matrix, meshgrid)\n\n    # generate a nonlinear transform\n    if chance(warp_probability):\n        disp = random_disp(\n            shape=shape,\n            smoothing=np.random.uniform(*warp_smoothing_range),\n            magnitude=np.random.uniform(*warp_magnitude_range),\n            integrations=warp_integrations,\n            voxsize=voxsize,\n            device=device,\n            perlin_method=perlin_method)\n\n        # merge with the affine transform if necessary\n        if trf is None:\n            trf = disp\n        else:\n            trf += spatial_transform(disp.movedim(-1, 0), trf, meshgrid=meshgrid).movedim(0, -1)\n\n    # convert to coordinates if specified\n    if trf is not None and not isdisp:\n        # compute the absolute crs field scaled to range [-1, 1]\n        trf = disp_to_coords(trf)\n\n    return trf\n</code></pre>"},{"location":"api/nn/functional/#voxelmorph.nn.functional.resize","title":"resize","text":"<pre><code>resize(image: Tensor, scale_factor: List[float] = None, shape: List[int] = None, nearest: bool = False) -&gt; Tensor\n</code></pre> <p>Resize an image with the option of scaling and/or setting to a new shape.</p> Parameters: <p>image: torch.Tensor     An input tensor with shape (C, H, W[, D]) to resize. scale_factor: float or List[float], optional     Multiplicative factor(s) for scaling the input tensor. If a float, then the same     scale factor is applied to all spatial dimensions. If a tuple, then the scaling     factor for each dimension should be provided. shape: List[int], optional     Target shape of the output tensor. nearest: bool, optional     If True, use nearest neighbor interpolation. Otherwise, use linear interpolation.</p> Returns: <p>torch.Tensor:     The resized tensor with the shape specified by <code>shape</code> or scaled by <code>scale_factor</code>.</p> Source code in <code>voxelmorph/nn/functional.py</code> <pre><code>def resize(\n    image: Tensor,\n    scale_factor: List[float] = None,\n    shape: List[int] = None,\n    nearest: bool = False\n) -&gt; Tensor:\n    \"\"\"\n    Resize an image with the option of scaling and/or setting to a new shape.\n\n    Parameters:\n    -----------\n    image: torch.Tensor\n        An input tensor with shape (C, H, W[, D]) to resize.\n    scale_factor: float or List[float], optional\n        Multiplicative factor(s) for scaling the input tensor. If a float, then the same\n        scale factor is applied to all spatial dimensions. If a tuple, then the scaling\n        factor for each dimension should be provided.\n    shape: List[int], optional\n        Target shape of the output tensor.\n    nearest: bool, optional\n        If True, use nearest neighbor interpolation. Otherwise, use linear interpolation.\n\n    Returns:\n    --------\n    torch.Tensor:\n        The resized tensor with the shape specified by `shape` or scaled by `scale_factor`.\n    \"\"\"\n    ndim = image.ndim - 1\n\n    # scale the image if the scale factor is provided\n    if scale_factor is not None and scale_factor != 1:\n\n        # compute target shape based on the scale factor\n        target_shape = [int(s * scale_factor + 0.5) for s in image.shape[1:]]\n\n        # convert image to float32 if it's not already to enable interpolation\n        # if using nearest interpolation, save the original dtype to convert back later\n        reset_type = None\n        if not torch.is_floating_point(image):\n            if nearest:\n                reset_type = image.dtype\n            image = image.type(torch.float32)\n\n        # determine interpolation mode based on ndim and interpolation type\n        linear = 'trilinear' if image.ndim - 1 == 3 else 'bilinear'\n        mode = 'nearest' if nearest else linear\n\n        # apply interpolation to the image\n        if nearest:\n            image = torch.nn.functional.interpolate(image.unsqueeze(0), target_shape, mode=mode)\n        else:\n            image = torch.nn.functional.interpolate(image.unsqueeze(0), target_shape, mode=mode)\n        image = image.squeeze(0)\n\n        # convert image back to its original dtype if necessary\n        if reset_type is not None:\n            image = image.type(reset_type)\n\n    if shape is not None:\n\n        # compute padding for each spatial dimension\n        padding = []\n        baseshape = image.shape[1:]\n        for d in range(ndim):\n            diff = shape[d] - baseshape[d]\n            if diff &gt; 0:\n                half = diff / 2\n                a, b = int(np.floor(half)), int(np.ceil(half))\n                padding.extend([a, b])\n            else:\n                padding.extend([0, 0])\n\n        # apply padding to the image\n        padding.reverse()\n        image = torch.nn.functional.pad(image, padding)\n\n        # compute slice to remove excess dimensions\n        slicing = [slice(0, image.shape[0])]\n        baseshape = image.shape[1:]\n        for d in range(ndim):\n            diff = baseshape[d] - shape[d]\n            if diff &gt; 0:\n                half = diff / 2\n                a, b = int(np.floor(half)), int(np.ceil(half))\n                slicing.append(slice(a, baseshape[d] - b))\n            else:\n                slicing.append(slice(0, baseshape[d]))\n\n        # apply slice to remove excess dimensions\n        image = image[tuple(slicing)]\n\n    return image\n</code></pre>"},{"location":"api/nn/functional/#voxelmorph.nn.functional.smooth_gaussian","title":"smooth_gaussian","text":"<pre><code>smooth_gaussian(shape, sigma, magnitude=1.0, device=None, method='blur')\n</code></pre> <p>Generates a smooth Gaussian noise image.</p> PARAMETER DESCRIPTION <code>shape</code> <p>The desired shape of the output tensor. Can be 2D or 3D.</p> <p> TYPE: <code>List[int]</code> </p> <code>sigma</code> <p>The spatial smoothing sigma in voxel coordinates.</p> <p> TYPE: <code>float</code> </p> <code>magnitude</code> <p>The standard deviation of the noise.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <code>device</code> <p>The device on which the output tensor is allocated. If None, defaults to CPU.</p> <p> TYPE: <code>device or None</code> DEFAULT: <code>None</code> </p> <code>method</code> <p>Method for noise generation. Upsampling is much faster and more memory efficient for larger sigma values, but at the cost of quality.</p> <p> TYPE: <code>blur or upsample</code> DEFAULT: <code>'blur'</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A smooth Gaussian noise image of shape <code>shape</code>.</p> Source code in <code>voxelmorph/nn/functional.py</code> <pre><code>def smooth_gaussian(shape, sigma, magnitude=1.0, device=None, method='blur'):\n    \"\"\"\n    Generates a smooth Gaussian noise image.\n\n    Parameters\n    ----------\n    shape : List[int]\n        The desired shape of the output tensor. Can be 2D or 3D.\n    sigma : float\n        The spatial smoothing sigma in voxel coordinates.\n    magnitude : float\n        The standard deviation of the noise.\n    device : torch.device or None, optional\n        The device on which the output tensor is allocated. If None, defaults to CPU.\n    method : 'blur' or 'upsample'\n        Method for noise generation. Upsampling is much faster and more memory efficient\n        for larger sigma values, but at the cost of quality.\n\n    Returns\n    -------\n    Tensor\n        A smooth Gaussian noise image of shape `shape`.\n    \"\"\"\n    if method == 'blur':\n        noise = torch.normal(0, 1, size=shape, device=device)\n        noise = gaussian_blur(noise.unsqueeze(0), sigma).squeeze(0)\n    elif method == 'upsample':\n        downshape = tuple([max(int(s // sigma), 2) for s in shape])\n        noise = torch.normal(0, 1, size=(1, 1, *downshape), device=device)\n        mode = 'trilinear' if len(shape) == 3 else 'bilinear'\n        noise = torch.nn.functional.interpolate(noise, shape, mode=mode).view(shape)\n    else:\n        raise ValueError(f'unknown smooth gaussian method `{method}`')\n\n    # in-place normalize\n    noise -= noise.mean()\n    noise *= magnitude / noise.std()\n    return noise\n</code></pre>"},{"location":"api/nn/functional/#voxelmorph.nn.functional.spatial_transform","title":"spatial_transform","text":"<pre><code>spatial_transform(image: Tensor, trf: Tensor, method: str = 'linear', isdisp: bool = True, meshgrid: Tensor = None, rotate_around_center: bool = True) -&gt; Tensor\n</code></pre> <p>TODOC</p> Source code in <code>voxelmorph/nn/functional.py</code> <pre><code>def spatial_transform(\n    image: Tensor,\n    trf: Tensor,\n    method: str = 'linear',\n    isdisp: bool = True,\n    meshgrid: Tensor = None,\n    rotate_around_center: bool = True\n) -&gt; Tensor:\n    \"\"\"\n    TODOC\n    \"\"\"\n    if trf is None:\n        return image\n\n    if trf.ndim == 2:\n        if meshgrid is None:\n            meshgrid = grid_coordinates(image.shape[1:], device=image.device)\n\n        trf = torch.linalg.inv(trf)\n        trf = affine_to_disp(\n            trf,\n            meshgrid,\n            rotate_around_center=rotate_around_center\n        )\n        isdisp = True\n\n    if isdisp:\n        # convert the displacement crs to absolute crs scaled to range [-1, 1]\n        trf = disp_to_coords(trf, meshgrid=meshgrid)\n\n    method = 'bilinear' if method == 'linear' else method\n\n    reset_type = None\n    if not torch.is_floating_point(image):\n        if method == 'nearest':\n            reset_type = image.dtype\n        image = image.type(torch.float32)\n\n    image = image.unsqueeze(0)\n    trf = trf.unsqueeze(0)\n\n    # trf is an absolute crs field in the range of [-1, 1]\n    interped = torch.nn.functional.grid_sample(image, trf, align_corners=True, mode=method)\n    interped = interped.squeeze(0)\n\n    if reset_type is not None:\n        interped = interped.type(reset_type)\n\n    return interped\n</code></pre>"},{"location":"api/nn/losses/","title":"nn.losses","text":""},{"location":"api/nn/losses/#voxelmorph.nn.losses","title":"voxelmorph.nn.losses","text":""},{"location":"api/nn/losses/#voxelmorph.nn.losses.Dice","title":"Dice","text":"<p>N-D dice for segmentation</p>"},{"location":"api/nn/losses/#voxelmorph.nn.losses.Grad","title":"Grad","text":"<pre><code>Grad(penalty='l1', loss_mult=None)\n</code></pre> <p>N-D gradient loss.</p> Source code in <code>voxelmorph/nn/losses.py</code> <pre><code>def __init__(self, penalty='l1', loss_mult=None):\n    self.penalty = penalty\n    self.loss_mult = loss_mult\n</code></pre>"},{"location":"api/nn/losses/#voxelmorph.nn.losses.MSE","title":"MSE","text":"<p>Mean squared error loss.</p>"},{"location":"api/nn/losses/#voxelmorph.nn.losses.NCC","title":"NCC","text":"<pre><code>NCC(win=None)\n</code></pre> <p>Local (over window) normalized cross correlation loss.</p> Source code in <code>voxelmorph/nn/losses.py</code> <pre><code>def __init__(self, win=None):\n    self.win = win\n</code></pre>"},{"location":"api/nn/models/","title":"nn.models","text":""},{"location":"api/nn/models/#voxelmorph.nn.models","title":"voxelmorph.nn.models","text":"<p>Models for the voxelmorph project.</p>"},{"location":"api/nn/models/#voxelmorph.nn.models.VxmDeformable","title":"VxmDeformable","text":"<pre><code>VxmDeformable(ndim: int, in_channels: int, out_channels: int, nb_features: List[int] = (16, 16, 16, 16, 16), normalizations: Union[List[Union[Callable, str]], Callable, str, None] = None, activations: Union[List[Union[Callable, str]], Callable, str, None] = nn.ReLU, order: str = 'caca', final_activation: Union[str, Module, None] = None, flow_initializer: Union[float, Sampler] = ne.samplers.Normal(0, 1e-05), bidirectional_cost: bool = False, integration_steps: int = 0, resize_integrated_fields: bool = False, device: str = 'cpu')\n</code></pre> <p>               Bases: <code>Module</code></p> <p>A network archetecture built on <code>BasicUNet</code> to perform nD image registration using a flow field.</p> PARAMETER DESCRIPTION <code>ndim</code> <p>Number of spatial dimensions (e.g., 2 for 2D, 3 for 3D).</p> <p> TYPE: <code>int</code> </p> <code>in_channels</code> <p>Number of input channels in the source and target images.</p> <p> TYPE: <code>int</code> </p> <code>out_channels</code> <p>Number of output channels in the displacement field.</p> <p> TYPE: <code>int</code> </p> <code>*args</code> <p>Additional positional arguments for the <code>BasicUNet</code> constructor.</p> <p> TYPE: <code>list</code> </p> <code>nb_features</code> <p>List of integers specifying the number of features in each level of the UNet architecture. Default is <code>[16, 16, 16, 16, 16]</code>.</p> <p> TYPE: <code>List[int]</code> DEFAULT: <code>(16, 16, 16, 16, 16)</code> </p> <code>normalizations</code> <p>Normalization layers for the UNet. Can be a list of normalization types or a single normalization type. Default is <code>None</code>.</p> <p> TYPE: <code>Union[List[str], str]</code> DEFAULT: <code>None</code> </p> <code>activations</code> <p>Activation functions for the UNet layers. Can be a list of activation functions or a single function. Default is <code>nn.ReLU</code>.</p> <p> TYPE: <code>Union[List[str], str]</code> DEFAULT: <code>ReLU</code> </p> <code>order</code> <p>The order of operations in each UNet block. Default is <code>'ncaca'</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'caca'</code> </p> <code>final_activation</code> <p>The activation applied to the final output of the network. Default is <code>None</code>.</p> <p> TYPE: <code>Union[str, Module, None]</code> DEFAULT: <code>None</code> </p> <code>flow_initializer</code> <p>A custom sampler for initializing the weights of the flow layer. If not provided, it defaults to a normal distribution with mean 0 and standard deviation <code>1e-5</code>.</p> <p> TYPE: <code>Sampler</code> DEFAULT: <code>Normal(0, 1e-05)</code> </p> <code>integration_steps</code> <p>Number of steps to take in integrating the flow field. Default is 1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>**kwargs</code> <p>Additional keyword arguments passed to the <code>BasicUNet</code> constructor.</p> <p> TYPE: <code>dict</code> </p> ATTRIBUTE DESCRIPTION <code>flow_layer</code> <p>A custom convolutional block used to generate the flow field from the combined source and target features.</p> <p> TYPE: <code>Module</code> </p> METHOD DESCRIPTION <code>forward</code> <p>Combines source and target images, processes them through the UNet and the flow layer, and returns the resulting flow field.</p> <p>Initialize the <code>VxmDeformable</code>.</p> PARAMETER DESCRIPTION <code>ndim</code> <p>Dimensionality of the input (1, 2, or 3).</p> <p> TYPE: <code>int</code> </p> <code>in_channels</code> <p>Number of input channels.</p> <p> TYPE: <code>int</code> </p> <code>out_channels</code> <p>Number of output channels.</p> <p> TYPE: <code>int</code> </p> <code>expected_moving_shape</code> <p>The expected shape of the <code>moving_tensor</code> input to the forward method of this class. without batch or channel dimensions. Used to initialize the <code>VecInt</code> integrator.</p> <p> TYPE: <code>tuple[int]</code> </p> <code>nb_features</code> <p>Number of features at each level of the unet. Must be a list of positive integers.</p> <p> TYPE: <code>List[int]</code> DEFAULT: <code>(16, 16, 16, 16, 16)</code> </p> <code>normalizations</code> <p>Normalization layers to use in each block. Can be a string or a list of strings specifying normalizations for each layer, or <code>None</code> for no norm.</p> <p> TYPE: <code>Union[List[str], str, None]</code> DEFAULT: <code>None</code> </p> <code>activations</code> <p>Activation functions to use in each block. Can be a callable, a string, or a list of strings/callables.</p> <p> TYPE: <code>Union[List[str], str, Callable]</code> DEFAULT: <code>ReLU</code> </p> <code>order</code> <p>The order of operations in each convolutional block. Default is 'cna' (normalization -&gt; convolution -&gt; activation). Each character in the string represents one of the following: - <code>'c'</code>: Convolution - <code>'n'</code>: Normalization - <code>'a'</code>: Activation</p> <p> TYPE: <code>str</code> DEFAULT: <code>'caca'</code> </p> <code>bidirectional_cost</code> <p>Enable calculation of the cost-function bidirectionally. Default is False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>integration_steps</code> <p>Number of scaling and squaring steps for integrating the flow field. Default is 0 (no integration).</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>device</code> <p>Device identifier (e.g., 'cpu' or 'cuda') to place/run the model on.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> Source code in <code>voxelmorph/nn/models.py</code> <pre><code>def __init__(\n    self,\n    ndim: int,\n    in_channels: int,\n    out_channels: int,\n    nb_features: List[int] = (16, 16, 16, 16, 16),\n    normalizations: Union[List[Union[Callable, str]], Callable, str, None] = None,\n    activations: Union[List[Union[Callable, str]], Callable, str, None] = nn.ReLU,\n    order: str = 'caca',\n    final_activation: Union[str, nn.Module, None] = None,\n    flow_initializer: Union[float, ne.samplers.Sampler] = ne.samplers.Normal(0, 1e-5),\n    bidirectional_cost: bool = False,\n    integration_steps: int = 0,\n    resize_integrated_fields: bool = False,\n    device: str = \"cpu\",\n):\n\n    \"\"\"\n    Initialize the `VxmDeformable`.\n\n    Parameters\n    ----------\n    ndim : int\n        Dimensionality of the input (1, 2, or 3).\n    in_channels : int\n        Number of input channels.\n    out_channels : int\n        Number of output channels.\n    expected_moving_shape : tuple[int]\n        The expected shape of the `moving_tensor` input to the forward method of this class.\n        without batch or channel dimensions. Used to initialize the `VecInt` integrator.\n    nb_features : List[int]\n        Number of features at each level of the unet. Must be a list of\n        positive integers.\n    normalizations : Union[List[str], str, None], optional\n        Normalization layers to use in each block. Can be a string or a list\n        of strings specifying normalizations for each layer, or `None` for no norm.\n    activations : Union[List[str], str, Callable], optional\n        Activation functions to use in each block. Can be a callable,\n        a string, or a list of strings/callables.\n    order : str, optional\n        The order of operations in each convolutional block. Default is 'cna'\n        (normalization -&gt; convolution -&gt; activation). Each character in the string represents\n        one of the following:\n        - `'c'`: Convolution\n        - `'n'`: Normalization\n        - `'a'`: Activation\n    bidirectional_cost : bool, optional\n        Enable calculation of the cost-function bidirectionally. Default is False\n    integration_steps : int, optional\n        Number of scaling and squaring steps for integrating the flow field.\n        Default is 0 (no integration).\n    device : str, optional\n        Device identifier (e.g., 'cpu' or 'cuda') to place/run the model on.\n    \"\"\"\n\n    # Initialize the Module\n    super().__init__()\n\n    # Set cnnstant attrs\n    self.integration_steps = integration_steps\n    self.bidirectional_cost = bidirectional_cost\n    self.resize_integrated_fields = resize_integrated_fields\n    self.device = device\n\n    # Set derived attrs\n    self._init_flow_layer(ndim, out_channels, flow_initializer)\n    self.model = ne.models.BasicUNet(\n        ndim=ndim, in_channels=in_channels, out_channels=out_channels, nb_features=nb_features,\n        normalizations=normalizations, activations=activations, order=order,\n        final_activation=final_activation\n    )\n</code></pre>"},{"location":"api/nn/models/#voxelmorph.nn.models.VxmDeformable._init_flow_layer","title":"_init_flow_layer","text":"<pre><code>_init_flow_layer(ndim: int, features: int, flow_initializer: Union[float, Sampler] = ne.samplers.Normal(0, 1e-05))\n</code></pre> <p>Initialize the flow layer with custom weight initialization (by sampling <code>flow_initializer</code>).</p> <p>This layer is a convolutional block that produces a displacement (flow) field. The weights of its initial convolution are sampled using the provided flow_initializer, and biases are set to zero.</p> PARAMETER DESCRIPTION <code>ndim</code> <p>Spatial dimensionality of the input (1, 2, or 3).</p> <p> TYPE: <code>int</code> </p> <code>features</code> <p>Number of input and output features for the flow layer.</p> <p> TYPE: <code>int</code> </p> <code>flow_initializer</code> <p>Sampler for initializing the weights of the flow layer. Default is <code>ne.random.Normal(0, 1e-5)</code>.</p> <p> TYPE: <code> Union[float, ne.random.Sampler]</code> DEFAULT: <code>Normal(0, 1e-05)</code> </p> Source code in <code>voxelmorph/nn/models.py</code> <pre><code>def _init_flow_layer(\n    self,\n    ndim: int,\n    features: int,\n    flow_initializer: Union[float, ne.samplers.Sampler] = ne.samplers.Normal(0, 1e-5)\n):\n\n    \"\"\"\n    Initialize the flow layer with custom weight initialization (by sampling\n    `flow_initializer`).\n\n    This layer is a convolutional block that produces a displacement (flow)\n    field. The weights of its initial convolution are sampled using the\n    provided flow_initializer, and biases are set to zero.\n\n    Parameters\n    ----------\n    ndim : int\n        **Spatial** dimensionality of the input (1, 2, or 3).\n    features : int\n        Number of input and output features for the flow layer.\n    flow_initializer :  Union[float, ne.random.Sampler], optional\n        Sampler for initializing the *weights* of the flow layer. Default is\n        `ne.random.Normal(0, 1e-5)`.\n    \"\"\"\n\n    # Initialize the conv (\"flow\") layer with congruent in and out features\n    flow_layer = ne.modules.ConvBlock(ndim, features, features).to(self.device)\n\n    # Optionally, apply custom initialization if `flow_initializer`` is provided\n    if flow_initializer is not None:\n\n        # Make the distribution to sample the flow parameters\n        flow_initializer = ne.samplers.Fixed.make(flow_initializer)\n\n        # Sample the weight parameters from the distribution for first (and only) conv\n        flow_layer.conv0.weight = nn.Parameter(\n            flow_initializer(flow_layer.conv0.weight.shape)\n        ).to(self.device)\n\n        # Set the bias term(s) to zero for the first (and only) conv\n        flow_layer.conv0.bias = nn.Parameter(\n            torch.zeros(flow_layer.conv0.bias.shape)\n        ).to(self.device)\n\n    # Register the flow layer as a submodule\n    self.add_module(\"flow_layer\", flow_layer)\n</code></pre>"},{"location":"api/nn/models/#voxelmorph.nn.models.VxmDeformable._integrate_velocity_fields","title":"_integrate_velocity_fields","text":"<pre><code>_integrate_velocity_fields(pos_flow: Tensor, neg_flow: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Integrate the velocity fields to obtain diffeomorphic warp (displacement) fields.</p> <p>Derive a smooth and invertable displacement field by integrating a velocity field via the scaling and squaring method. If no <code>IntegrateVelocityField</code> object exists in the model's state dictionary, instantiate it with the correct size of the input and insert it. This will only happen once upon initial call of this method.</p> PARAMETER DESCRIPTION <code>pos_flow</code> <p>Positive flow (velocity) field (source -&gt; target).</p> <p> TYPE: <code>Tensor</code> </p> <code>neg_flow</code> <p>Negative flow (velocity) field (target -&gt; source).</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Displacement field obtained by integrating the velocity field via scaling and squaring.</p> Source code in <code>voxelmorph/nn/models.py</code> <pre><code>def _integrate_velocity_fields(\n    self,\n    pos_flow: torch.Tensor,\n    neg_flow: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Integrate the velocity fields to obtain diffeomorphic warp (displacement) fields.\n\n    Derive a smooth and invertable displacement field by integrating a velocity field via the\n    scaling and squaring method. If no `IntegrateVelocityField` object exists in the model's\n    state dictionary, instantiate it with the correct size of the input and insert it. This will\n    only happen once upon initial call of this method.\n\n    Parameters\n    ----------\n    pos_flow : torch.Tensor\n        Positive flow (velocity) field (source -&gt; target).\n    neg_flow : torch.Tensor\n        Negative flow (velocity) field (target -&gt; source).\n\n    Returns\n    -------\n    torch.Tensor\n        Displacement field obtained by integrating the velocity field via scaling and squaring.\n    \"\"\"\n\n    # If the velocity integrator is not defined, dynamically construct it\n    if not hasattr(self, \"velocity_field_integrator\"):\n\n        # Dynamically construct the integrator based on the spatial shape\n        velocity_field_integrator = vxm.nn.modules.IntegrateVelocityField(\n            shape=pos_flow.shape[2:], steps=self.integration_steps, device=self.device\n        )\n\n        # Add it to the module\n        self.add_module(\"velocity_field_integrator\", velocity_field_integrator)\n\n    # Integrate the positive flow\n    pos_flow = self.velocity_field_integrator(pos_flow)\n\n    # Integrate the negative velocity field if bidirectional cost is enabled\n    neg_flow = self.velocity_field_integrator(neg_flow) if self.bidirectional_cost else None\n\n    return pos_flow, neg_flow\n</code></pre>"},{"location":"api/nn/models/#voxelmorph.nn.models.VxmDeformable._spatial_transform","title":"_spatial_transform","text":"<pre><code>_spatial_transform(moving_image: Tensor, deformation_field: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Warp an image tensor using a deformation/displacement field.</p> <p>This method applies a spatial transformation to the provided image tensor based on the deformation field using a SpatialTransformer. If no <code>IntegrateVelocityField</code> object exists in the model's state dictionary, instantiate one with the correct size of the input and register it as a submodule. This will only happen once upon the initial call of this method.</p> PARAMETER DESCRIPTION <code>moving_image</code> <p>Image tensor to be warped, with shape (B, C, ...).</p> <p> TYPE: <code>Tensor</code> </p> <code>deformation_field</code> <p>Displacement field used for warping, with shape matching the spatial dimensions of <code>moving_image</code>.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>The warped image tensor.</p> Source code in <code>voxelmorph/nn/models.py</code> <pre><code>def _spatial_transform(\n    self,\n    moving_image: torch.Tensor,\n    deformation_field: torch.Tensor\n) -&gt; torch.Tensor:\n    \"\"\"\n    Warp an image tensor using a deformation/displacement field.\n\n    This method applies a spatial transformation to the provided image tensor based on the\n    deformation field using a SpatialTransformer. If no `IntegrateVelocityField` object exists\n    in the model's state dictionary, instantiate one with the correct size of the input and\n    register it as a submodule. This will only happen once upon the initial call of this method.\n\n    Parameters\n    ----------\n    moving_image : torch.Tensor\n        Image tensor to be warped, with shape (B, C, ...).\n    deformation_field : torch.Tensor\n        Displacement field used for warping, with shape matching the spatial dimensions of\n        `moving_image`.\n\n    Returns\n    -------\n    torch.Tensor\n        The warped image tensor.\n    \"\"\"\n\n    if not hasattr(self, \"spatial_transformer\"):\n        # Dynamically construct the spatial transformer with the correct spatial shape\n        spatial_transformer = vxm.nn.modules.SpatialTransformer(\n            size=moving_image.shape[2:], device=self.device\n        )\n\n        # Register it as a submodule\n        self.add_module(\"spatial_transformer\", spatial_transformer)\n\n    # Warp the moving image with the deformation field\n    warped_image = self.spatial_transformer(moving_image, deformation_field)\n\n    return warped_image\n</code></pre>"},{"location":"api/nn/modules/","title":"nn.modules","text":""},{"location":"api/nn/modules/#voxelmorph.nn.modules","title":"voxelmorph.nn.modules","text":""},{"location":"api/nn/modules/#voxelmorph.nn.modules.IntegrateVelocityField","title":"IntegrateVelocityField","text":"<pre><code>IntegrateVelocityField(shape: tuple, steps: int = 1, interpolation_mode: str = 'bilinear', align_corners: bool = False, device: str = 'cpu')\n</code></pre> <p>               Bases: <code>Module</code></p> <p>Integrates a velocity field over multiple steps using the scaling and squaring method.</p> <p>This module ensures that transformations caused by a velocity field is diffeomorphic by compounding small, intermediate transformations (by recursive scaling and squaring). This ensures the resultant is both smooth and invertable.</p> ATTRIBUTE DESCRIPTION <code>steps</code> <p>The number of squaring steps used for integration.</p> <p> TYPE: <code>int</code> </p> <code>scale</code> <p>Scaling factor for the initial velocity field, determined as <code>1 / (2^steps)</code>.</p> <p> TYPE: <code>float</code> </p> <code>transformer</code> <p>A spatial transformer module used to iteratively warp the vector field.</p> <p> TYPE: <code>Module</code> </p> <p>Examples:</p>"},{"location":"api/nn/modules/#voxelmorph.nn.modules.IntegrateVelocityField--integrate-a-2d-velocity-field-over-multiple-steps","title":"Integrate a 2D velocity field over multiple steps:","text":"<pre><code>&gt;&gt;&gt; shape = (128, 128)  # 2D spatial grid\n&gt;&gt;&gt; integrator = IntegrateVelocityField(shape, steps=256)\n&gt;&gt;&gt; velocity_field = torch.randn(1, 2, 128, 128)  # (B, C, H, W)\n&gt;&gt;&gt; disp = integrator(velocity_field)\n&gt;&gt;&gt; disp.shape\ntorch.Size([1, 2, 128, 128])\n</code></pre>"},{"location":"api/nn/modules/#voxelmorph.nn.modules.IntegrateVelocityField--perform-integration-on-a-3d-velocity-field-with-a-single-scaling-step","title":"Perform integration on a 3D velocity field with a single scaling step:","text":"<pre><code>&gt;&gt;&gt; shape = (64, 64, 64)  # 3D spatial grid\n&gt;&gt;&gt; integrator = IntegrateVelocityField(shape, steps=1)\n&gt;&gt;&gt; velocity_field = torch.randn(1, 3, 64, 64, 64)  # (B, C, D, H, W)\n&gt;&gt;&gt; disp = integrator(velocity_field)\n&gt;&gt;&gt; disp.shape\ntorch.Size([1, 3, 64, 64, 64])\n</code></pre> <p>Initialize <code>IntegrateVelocityField</code></p> PARAMETER DESCRIPTION <code>shape</code> <p>Shape of the input velocity field (excluding batch and channel dimensions).</p> <p> TYPE: <code>tuple</code> </p> <code>steps</code> <p>Number of integration steps. A higher value leads to a more smooth and accurate integration at the cost of higher/longer computation. Default is 1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>interpolation_mode</code> <p>Algorithm used for interpolating the warped image. Default is  'bilinear'. Options are: 'bilinear' | 'nearest' | 'bicubic'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'bilinear'</code> </p> <code>align_corners</code> <p>Map the corner points of the moving image to the corner points of the warped image.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>device</code> <p>Device to construct and hold the identity grid.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> Source code in <code>voxelmorph/nn/modules.py</code> <pre><code>def __init__(\n    self, shape: tuple,\n    steps: int = 1,\n    interpolation_mode: str = \"bilinear\",\n    align_corners: bool = False,\n    device: str = \"cpu\"\n):\n    \"\"\"\n    Initialize `IntegrateVelocityField`\n\n    Parameters\n    ----------\n    shape : tuple\n        Shape of the input velocity field (excluding batch and channel dimensions).\n    steps : int, optional\n        Number of integration steps. A higher value leads to a more smooth and accurate\n        integration at the cost of higher/longer computation. Default is 1.\n    interpolation_mode : str\n        Algorithm used for interpolating the warped image. Default is  'bilinear'. Options are:\n        'bilinear' | 'nearest' | 'bicubic'.\n    align_corners : bool\n        Map the corner points of the moving image to the corner points of the warped image.\n    device : str\n        Device to construct and hold the identity grid.\n    \"\"\"\n\n    super().__init__()\n\n    if steps &lt; 0:\n        raise ValueError(f\"steps should be &gt;= 0, found: {steps}\")\n\n    self.steps = steps\n    self.scale = 1.0 / (2 ** self.steps)  # Initial downscaling factor\n\n    # Make the transformer which will perform the warping operation\n    self.transformer = SpatialTransformer(shape, interpolation_mode, align_corners, device)\n</code></pre>"},{"location":"api/nn/modules/#voxelmorph.nn.modules.ResizeDisplacementField","title":"ResizeDisplacementField","text":"<pre><code>ResizeDisplacementField(scale_factor: Optional[Union[float, int, Sampler]] = 1.0, interpolation_mode: str = 'bilinear', align_corners: bool = True)\n</code></pre> <p>               Bases: <code>Module</code></p> <p>Resize and rescale a displacement field.</p> <p>Resizd a displacement field both spatially (via interpolation) and in magnitude (via scaling).</p> <p>Examples:</p>"},{"location":"api/nn/modules/#voxelmorph.nn.modules.ResizeDisplacementField--resize-a-2d-displacement-field","title":"Resize a 2D displacement field","text":"<pre><code>&gt;&gt;&gt; resize_field = ResizeDisplacementField(scale_factor=2.0, interpolation_mode=\"bilinear\")\n&gt;&gt;&gt; disp = torch.rand(1, 2, 16, 16)  # Example displacement field in 2d\n&gt;&gt;&gt; resized_disp = resize_field(disp)\n&gt;&gt;&gt; print(resized_disp.shape)  # Should be larger if scale_factor &gt; 1\ntorch.Size([1, 2, 32, 32])\n</code></pre> <p>Instantiate the <code>ResizeDisplacementField</code> module.</p> PARAMETER DESCRIPTION <code>scale_factor</code> <p>Factor by which to stretch or shrink the spatial dimensions of the displacement field. Values of <code>scale_factor</code> &gt; 1 stretch/expand the field, and values &lt; 1 shrink it. By default None.</p> <p> TYPE: <code>Optional[Union[float, int, Sampler]]</code> DEFAULT: <code>1.0</code> </p> <code>interpolation_mode</code> <p>Algorithm used for interpolating the warped image. Default is  'bilinear'. Options are: 'bilinear' | 'nearest' | 'bicubic', 'trilinear'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'bilinear'</code> </p> <code>align_corners</code> <p>Map the corner points of the moving image to the corner points of the warped image.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Source code in <code>voxelmorph/nn/modules.py</code> <pre><code>def __init__(\n    self,\n    scale_factor: Optional[Union[float, int, ne.samplers.Sampler]] = 1.0,\n    interpolation_mode: str = \"bilinear\",\n    align_corners: bool = True,\n):\n    \"\"\"\n    Instantiate the `ResizeDisplacementField` module.\n\n    Parameters\n    ----------\n    scale_factor : Optional[Union[float, int, Sampler]], optional\n        Factor by which to stretch or shrink the spatial dimensions of the displacement field.\n        Values of `scale_factor` &gt; 1 stretch/expand the field, and values &lt; 1 shrink it. By\n        default None.\n    interpolation_mode : str\n        Algorithm used for interpolating the warped image. Default is  'bilinear'. Options are:\n        'bilinear' | 'nearest' | 'bicubic', 'trilinear'.\n    align_corners : bool\n        Map the corner points of the moving image to the corner points of the warped image.\n    \"\"\"\n    super().__init__()\n    self.interpolation_mode = interpolation_mode\n    self.align_corners = align_corners\n    self.scale_factor = ne.samplers.Fixed.make(scale_factor)\n</code></pre>"},{"location":"api/nn/modules/#voxelmorph.nn.modules.SpatialTransformer","title":"SpatialTransformer","text":"<pre><code>SpatialTransformer(size: Tuple[int], interpolation_mode: str = 'bilinear', align_corners: bool = False, device: Union[str, device] = 'cpu')\n</code></pre> <p>               Bases: <code>Module</code></p> <p>N-D Spatial transformation according to a deformation field.</p> <p>Uses a deformation field to transform the moving image.</p> References <p>If you find this helpful, please cite the following paper:</p> <p>VoxelMorph: A Learning Framework for Deformable Medical Image Registration G. Balakrishnan, A. Zhao, M. R. Sabuncu, J. Guttag, A.V. Dalca.  IEEE TMI: Transactions on Medical Imaging. 38(8). pp 1788-1800. 2019.</p> <p>Initialize <code>SpatialTransformer</code>.</p> PARAMETER DESCRIPTION <code>size</code> <p>Expected size of <code>moving_image</code> (input image to be warped) for the forward pass.</p> <p> TYPE: <code>tuple[int]</code> </p> <code>interpolation_mode</code> <p>Algorithm used for interpolating the warped image. Default is  'bilinear'. Options are: 'bilinear' | 'nearest' | 'bicubic'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'bilinear'</code> </p> <code>align_corners</code> <p>Map the corner points of the moving image to the corner points of the warped image.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>device</code> <p>Device to construct and hold the identity grid.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> Source code in <code>voxelmorph/nn/modules.py</code> <pre><code>def __init__(\n    self,\n    size: Tuple[int],\n    interpolation_mode: str = \"bilinear\",\n    align_corners: bool = False,\n    device: Union[str, torch.device] = \"cpu\",\n):\n    \"\"\"\n    Initialize `SpatialTransformer`.\n\n    Parameters\n    ----------\n    size : tuple[int]\n        Expected size of `moving_image` (input image to be warped) for the forward pass.\n    interpolation_mode : str\n        Algorithm used for interpolating the warped image. Default is  'bilinear'. Options are:\n        'bilinear' | 'nearest' | 'bicubic'.\n    align_corners : bool\n        Map the corner points of the moving image to the corner points of the warped image.\n    device : str\n        Device to construct and hold the identity grid.\n    \"\"\"\n    super().__init__()\n\n    self.size = size\n    self.device = device\n    self.interpolation_mode = interpolation_mode\n    self.align_corners = align_corners\n\n    # Make identity grid (the grid to later warp with deformation field) and register as a\n    # buffer (without saving to `state_dict`: persistent=False)\n    self.register_buffer(\n        name='identity_grid',\n        tensor=ne.utils.utils.grid(size=size, device=device),\n        persistent=False  # Don't save to this module's state dict!\n    )\n</code></pre>"},{"location":"api/nn/modules/#voxelmorph.nn.modules.SpatialTransformer._normalize_warped_grid","title":"_normalize_warped_grid","text":"<pre><code>_normalize_warped_grid(warped_grid: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Normalize a warped grid to make PyTorch <code>grid_sample()</code> happy!</p> <p>PyTorch's <code>grid_sample()</code> requires coordinates in the range [-1, 1]. This function scales and shifts the warped grid accordingly.</p> PARAMETER DESCRIPTION <code>warped_grid</code> <p>The resultant of the identity grid and the deformation field.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>The warped grid rescaled to the range [-1, 1] for each spatial axis</p> Source code in <code>voxelmorph/nn/modules.py</code> <pre><code>def _normalize_warped_grid(\n    self,\n    warped_grid: torch.Tensor\n) -&gt; torch.Tensor:\n    \"\"\"\n    Normalize a warped grid to make PyTorch `grid_sample()` happy!\n\n    PyTorch's `grid_sample()` requires coordinates in the range [-1, 1].\n    This function scales and shifts the warped grid accordingly.\n\n    Parameters\n    ----------\n    warped_grid : torch.Tensor\n        The resultant of the identity grid and the deformation field.\n\n    Returns\n    -------\n    torch.Tensor\n        The warped grid rescaled to the range [-1, 1] for each spatial axis\n    \"\"\"\n\n    for i, dim in enumerate(self.size):\n\n        # Rescale each dimension individually\n        warped_grid[..., i] = 2 * (warped_grid[..., i] / (dim - 1) - 0.5)\n\n    return warped_grid\n</code></pre>"},{"location":"api/nn/nn/","title":"nn","text":""},{"location":"api/nn/nn/#voxelmorph.nn","title":"voxelmorph.nn","text":"<p>Torch-based neural network components for VoxelMorph. This subpackage contains the functional operators, reusable building blocks, model definitions, and loss functions to implement the VoxelMorph framework in PyTorch.</p> MODULE DESCRIPTION <code>functional</code> <p>Functions containing the core operations and logic of for image registration written in PyTorch.</p> <code>losses</code> <p>Loss functions for image registration.</p> <code>models</code> <p>Core VoxelMorph models for unsupervised and supervised learning.</p> <code>modules</code> <p>Neural network building blocks for VoxelMorph.</p>"},{"location":"api/py/generators/","title":"py.generators","text":""},{"location":"api/py/generators/#voxelmorph.py.generators","title":"voxelmorph.py.generators","text":""},{"location":"api/py/generators/#voxelmorph.py.generators.conditional_template_creation","title":"conditional_template_creation","text":"<pre><code>conditional_template_creation(vol_names, atlas, attributes, batch_size=1, np_var='vol', pad_shape=None, add_feat_axis=True)\n</code></pre> <p>Generator for conditional template creation.</p> <p>Parameters:     vol_names: List of volume files to load, or list of preloaded volumes.     atlas: Atlas input volume data.     attributes: Dictionary of phenotype data for each vol name.     batch_size: Batch size. Default is 1.     np_var: Name of the volume variable if loading npz files. Default is 'vol'.     pad_shape: Zero-pads loaded volumes to a given shape. Default is None.     add_feat_axis: Load volume arrays with added feature axis. Default is True.</p> Source code in <code>voxelmorph/py/generators.py</code> <pre><code>def conditional_template_creation(vol_names, atlas, attributes,\n                                  batch_size=1, np_var='vol', pad_shape=None, add_feat_axis=True):\n    \"\"\"\n    Generator for conditional template creation.\n\n    Parameters:\n        vol_names: List of volume files to load, or list of preloaded volumes.\n        atlas: Atlas input volume data.\n        attributes: Dictionary of phenotype data for each vol name.\n        batch_size: Batch size. Default is 1.\n        np_var: Name of the volume variable if loading npz files. Default is 'vol'.\n        pad_shape: Zero-pads loaded volumes to a given shape. Default is None.\n        add_feat_axis: Load volume arrays with added feature axis. Default is True.\n    \"\"\"\n    shape = atlas.shape[1:-1]\n    zeros = np.zeros((batch_size, *shape, len(shape)))\n    atlas = np.repeat(atlas, batch_size, axis=0)\n    while True:\n        indices = np.random.randint(len(vol_names), size=batch_size)\n\n        # load pheno from attributes dictionary\n        pheno = np.stack([attributes[vol_names[i]] for i in indices], axis=0)\n\n        # load volumes and concatenate\n        load_params = dict(np_var=np_var, add_batch_axis=True,\n                           add_feat_axis=add_feat_axis, pad_shape=pad_shape)\n        vols = [vxm.py.utils.load_volfile(vol_names[i], **load_params) for i in indices]\n        vols = np.concatenate(vols, axis=0)\n\n        invols = [pheno, atlas, vols]\n        outvols = [vols, zeros, zeros, zeros]\n        yield (invols, outvols)\n</code></pre>"},{"location":"api/py/generators/#voxelmorph.py.generators.scan_to_atlas","title":"scan_to_atlas","text":"<pre><code>scan_to_atlas(vol_names, atlas, bidir=False, batch_size=1, no_warp=False, segs=None, **kwargs)\n</code></pre> <p>Generator for scan-to-atlas registration.</p> <p>TODO: This could be merged into scan_to_scan() by adding an optional atlas argument like in semisupervised().</p> <p>Parameters:     vol_names: List of volume files to load, or list of preloaded volumes.     atlas: Atlas volume data.     bidir: Yield input image as output for bidirectional models. Default is False.     batch_size: Batch size. Default is 1.     no_warp: Excludes null warp in output list if set to True (for affine training).          Default is False.     segs: Load segmentations as output, for supervised training. Forwarded to the         internal volgen generator. Default is None.     kwargs: Forwarded to the internal volgen generator.</p> Source code in <code>voxelmorph/py/generators.py</code> <pre><code>def scan_to_atlas(vol_names, atlas, bidir=False, batch_size=1, no_warp=False, segs=None, **kwargs):\n    \"\"\"\n    Generator for scan-to-atlas registration.\n\n    TODO: This could be merged into scan_to_scan() by adding an optional atlas\n    argument like in semisupervised().\n\n    Parameters:\n        vol_names: List of volume files to load, or list of preloaded volumes.\n        atlas: Atlas volume data.\n        bidir: Yield input image as output for bidirectional models. Default is False.\n        batch_size: Batch size. Default is 1.\n        no_warp: Excludes null warp in output list if set to True (for affine training). \n            Default is False.\n        segs: Load segmentations as output, for supervised training. Forwarded to the\n            internal volgen generator. Default is None.\n        kwargs: Forwarded to the internal volgen generator.\n    \"\"\"\n    shape = atlas.shape[1:-1]\n    zeros = np.zeros((batch_size, *shape, len(shape)))\n    atlas = np.repeat(atlas, batch_size, axis=0)\n    gen = volgen(vol_names, batch_size=batch_size, segs=segs, **kwargs)\n    while True:\n        res = next(gen)\n        scan = res[0]\n        invols = [scan, atlas]\n        if not segs:\n            outvols = [atlas, scan] if bidir else [atlas]\n        else:\n            seg = res[1]\n            outvols = [seg, scan] if bidir else [seg]\n        if not no_warp:\n            outvols.append(zeros)\n        yield (invols, outvols)\n</code></pre>"},{"location":"api/py/generators/#voxelmorph.py.generators.scan_to_scan","title":"scan_to_scan","text":"<pre><code>scan_to_scan(vol_names, bidir=False, batch_size=1, prob_same=0, no_warp=False, **kwargs)\n</code></pre> <p>Generator for scan-to-scan registration.</p> <p>Parameters:     vol_names: List of volume files to load, or list of preloaded volumes.     bidir: Yield input image as output for bidirectional models. Default is False.     batch_size: Batch size. Default is 1.     prob_same: Induced probability that source and target inputs are the same. Default is 0.     no_warp: Excludes null warp in output list if set to True (for affine training).          Default if False.     kwargs: Forwarded to the internal volgen generator.</p> Source code in <code>voxelmorph/py/generators.py</code> <pre><code>def scan_to_scan(vol_names, bidir=False, batch_size=1, prob_same=0, no_warp=False, **kwargs):\n    \"\"\"\n    Generator for scan-to-scan registration.\n\n    Parameters:\n        vol_names: List of volume files to load, or list of preloaded volumes.\n        bidir: Yield input image as output for bidirectional models. Default is False.\n        batch_size: Batch size. Default is 1.\n        prob_same: Induced probability that source and target inputs are the same. Default is 0.\n        no_warp: Excludes null warp in output list if set to True (for affine training). \n            Default if False.\n        kwargs: Forwarded to the internal volgen generator.\n    \"\"\"\n    zeros = None\n    gen = volgen(vol_names, batch_size=batch_size, **kwargs)\n    while True:\n        scan1 = next(gen)[0]\n        scan2 = next(gen)[0]\n\n        # some induced chance of making source and target equal\n        if prob_same &gt; 0 and np.random.rand() &lt; prob_same:\n            if np.random.rand() &gt; 0.5:\n                scan1 = scan2\n            else:\n                scan2 = scan1\n\n        # cache zeros\n        if not no_warp and zeros is None:\n            shape = scan1.shape[1:-1]\n            zeros = np.zeros((batch_size, *shape, len(shape)))\n\n        invols = [scan1, scan2]\n        outvols = [scan2, scan1] if bidir else [scan2]\n        if not no_warp:\n            outvols.append(zeros)\n\n        yield (invols, outvols)\n</code></pre>"},{"location":"api/py/generators/#voxelmorph.py.generators.semisupervised","title":"semisupervised","text":"<pre><code>semisupervised(vol_names, seg_names, labels, atlas_file=None, downsize=2)\n</code></pre> <p>Generator for semi-supervised registration training using ground truth segmentations. Scan-to-atlas training can be enabled by providing the atlas_file argument. </p> <p>Parameters:     vol_names: List of volume files to load, or list of preloaded volumes.     seg_names: List of corresponding seg files to load, or list of preloaded volumes.     labels: Array of discrete label values to use in training.     atlas_file: Atlas npz file for scan-to-atlas training. Default is None.     downsize: Downsize factor for segmentations. Default is 2.</p> Source code in <code>voxelmorph/py/generators.py</code> <pre><code>def semisupervised(vol_names, seg_names, labels, atlas_file=None, downsize=2):\n    \"\"\"\n    Generator for semi-supervised registration training using ground truth segmentations.\n    Scan-to-atlas training can be enabled by providing the atlas_file argument. \n\n    Parameters:\n        vol_names: List of volume files to load, or list of preloaded volumes.\n        seg_names: List of corresponding seg files to load, or list of preloaded volumes.\n        labels: Array of discrete label values to use in training.\n        atlas_file: Atlas npz file for scan-to-atlas training. Default is None.\n        downsize: Downsize factor for segmentations. Default is 2.\n    \"\"\"\n    # configure base generator\n    gen = volgen(vol_names, segs=seg_names, np_var='vol')\n    zeros = None\n\n    # internal utility to generate downsampled prob seg from discrete seg\n    def split_seg(seg):\n        prob_seg = np.zeros((*seg.shape[:4], len(labels)))\n        for i, label in enumerate(labels):\n            prob_seg[0, ..., i] = seg[0, ..., 0] == label\n        return prob_seg[:, ::downsize, ::downsize, ::downsize, :]\n\n    # cache target vols and segs if atlas is supplied\n    if atlas_file:\n        trg_vol = vxm.py.utils.load_volfile(atlas_file, np_var='vol',\n                                        add_batch_axis=True, add_feat_axis=True)\n        trg_seg = vxm.py.utils.load_volfile(atlas_file, np_var='seg',\n                                        add_batch_axis=True, add_feat_axis=True)\n        trg_seg = split_seg(trg_seg)\n\n    while True:\n        # load source vol and seg\n        src_vol, src_seg = next(gen)\n        src_seg = split_seg(src_seg)\n\n        # load target vol and seg (if not provided by atlas)\n        if not atlas_file:\n            trg_vol, trg_seg = next(gen)\n            trg_seg = split_seg(trg_seg)\n\n        # cache zeros\n        if zeros is None:\n            shape = src_vol.shape[1:-1]\n            zeros = np.zeros((1, *shape, len(shape)))\n\n        invols = [src_vol, trg_vol, src_seg]\n        outvols = [trg_vol, zeros, trg_seg]\n        yield (invols, outvols)\n</code></pre>"},{"location":"api/py/generators/#voxelmorph.py.generators.surf_semisupervised","title":"surf_semisupervised","text":"<pre><code>surf_semisupervised(vol_names, atlas_vol, atlas_seg, nb_surface_pts, labels=None, batch_size=1, surf_bidir=True, surface_pts_upsample_factor=2, smooth_seg_std=1, nb_labels_sample=None, sdt_vol_resize=1, align_segs=False, add_feat_axis=True)\n</code></pre> <p>Scan-to-atlas generator for semi-supervised learning using surface point clouds  from segmentations.</p> <p>Parameters:     vol_names: List of volume files to load.     atlas_vol: Atlas volume array.     atlas_seg: Atlas segmentation array.     nb_surface_pts: Total number surface points for all structures.     labels: Label list to include. If None, all labels in atlas_seg are used. Default is None.     batch_size: Batch size. NOTE some features only implemented for 1. Default is 1.     surf_bidir: Train with bidirectional surface distance. Default is True.     surface_pts_upsample_factor: Upsample factor for surface pointcloud. Default is 2.     smooth_seg_std: Segmentation smoothness sigma. Default is 1.     nb_labels_sample: Number of labels to sample. Default is None.     sdt_vol_resize: Resize factor for signed distance transform volumes. Default is 1.     align_segs: Whether to pass in segmentation image instead. Default is False.     add_feat_axis: Load volume arrays with added feature axis. Default is True.</p> Source code in <code>voxelmorph/py/generators.py</code> <pre><code>def surf_semisupervised(\n    vol_names,\n    atlas_vol,\n    atlas_seg,\n    nb_surface_pts,\n    labels=None,\n    batch_size=1,\n    surf_bidir=True,\n    surface_pts_upsample_factor=2,\n    smooth_seg_std=1,\n    nb_labels_sample=None,\n    sdt_vol_resize=1,\n    align_segs=False,\n    add_feat_axis=True\n):\n    \"\"\"\n    Scan-to-atlas generator for semi-supervised learning using surface point clouds \n    from segmentations.\n\n    Parameters:\n        vol_names: List of volume files to load.\n        atlas_vol: Atlas volume array.\n        atlas_seg: Atlas segmentation array.\n        nb_surface_pts: Total number surface points for all structures.\n        labels: Label list to include. If None, all labels in atlas_seg are used. Default is None.\n        batch_size: Batch size. NOTE some features only implemented for 1. Default is 1.\n        surf_bidir: Train with bidirectional surface distance. Default is True.\n        surface_pts_upsample_factor: Upsample factor for surface pointcloud. Default is 2.\n        smooth_seg_std: Segmentation smoothness sigma. Default is 1.\n        nb_labels_sample: Number of labels to sample. Default is None.\n        sdt_vol_resize: Resize factor for signed distance transform volumes. Default is 1.\n        align_segs: Whether to pass in segmentation image instead. Default is False.\n        add_feat_axis: Load volume arrays with added feature axis. Default is True.\n    \"\"\"\n\n    # some input checks\n    assert nb_surface_pts &gt; 0, 'number of surface point should be greater than 0'\n\n    # prepare some shapes\n    vol_shape = atlas_seg.shape\n    sdt_shape = [int(f * sdt_vol_resize) for f in vol_shape]\n\n    # compute labels from atlas, and the number of labels to sample.\n    if labels is not None:\n        atlas_seg = vxm.py.utils.filter_labels(atlas_seg, labels)\n    else:\n        labels = np.sort(np.unique(atlas_seg))[1:]\n\n    # use all labels by default\n    if nb_labels_sample is None:\n        nb_labels_sample = len(labels)\n\n    # prepare keras format atlases\n    atlas_vol_bs = np.repeat(atlas_vol[np.newaxis, ..., np.newaxis], batch_size, axis=0)\n    atlas_seg_bs = np.repeat(atlas_seg[np.newaxis, ..., np.newaxis], batch_size, axis=0)\n\n    # prepare surface extraction function\n    std_to_surf = lambda x, y: vxm.py.utils.sdt_to_surface_pts(\n        x, y,\n        surface_pts_upsample_factor=surface_pts_upsample_factor,\n        thr=(1 / surface_pts_upsample_factor + 1e-5))\n\n    # prepare zeros, which will be used for outputs unused in cost functions\n    zero_flow = np.zeros((batch_size, *vol_shape, len(vol_shape)))\n    zero_surface_values = np.zeros((batch_size, nb_surface_pts, 1))\n\n    # precompute label edge volumes\n    atlas_sdt = [None] * len(labels)\n    atlas_label_vols = [None] * len(labels)\n    nb_edges = np.zeros(len(labels))\n    for li, label in enumerate(labels):  # if only one label, get surface points here\n        atlas_label_vols[li] = atlas_seg == label\n        atlas_label_vols[li] = vxm.py.utils.clean_seg(atlas_label_vols[li], smooth_seg_std)\n        atlas_sdt[li] = vxm.py.utils.vol_to_sdt(\n            atlas_label_vols[li], sdt=True, sdt_vol_resize=sdt_vol_resize)\n        nb_edges[li] = np.sum(np.abs(atlas_sdt[li]) &lt; 1.01)\n    layer_edge_ratios = nb_edges / np.sum(nb_edges)\n\n    # if working with all the labels passed in (i.e. no label sampling per batch),\n    # pre-compute the atlas surface points\n    atlas_surface_pts = np.zeros((batch_size, nb_surface_pts, len(vol_shape) + 1))\n    if nb_labels_sample == len(labels):\n        nb_surface_pts_sel = vxm.py.utils.get_surface_pts_per_label(nb_surface_pts, layer_edge_ratios)\n        for li, label in enumerate(labels):  # if only one label, get surface points here\n            atlas_surface_pts_ = std_to_surf(atlas_sdt[li], nb_surface_pts_sel[li])[np.newaxis, ...]\n            # get the surface point stack indexes for this element\n            srf_idx = slice(int(np.sum(nb_surface_pts_sel[:li])), int(\n                np.sum(nb_surface_pts_sel[:li + 1])))\n            atlas_surface_pts[:, srf_idx, :-1] = np.repeat(atlas_surface_pts_, batch_size, 0)\n            atlas_surface_pts[:, srf_idx, -1] = li\n\n    # generator\n    gen = volgen(vol_names, segs=True, batch_size=batch_size, add_feat_axis=add_feat_axis)\n\n    assert batch_size == 1, 'only batch size 1 supported for now'\n\n    while True:\n\n        # prepare data\n        X = next(gen)\n        X_img = X[0]\n        X_seg = vxm.py.utils.filter_labels(X[1], labels)\n\n        # get random labels\n        sel_label_idxs = range(len(labels))  # all labels\n        if nb_labels_sample != len(labels):\n            sel_label_idxs = np.sort(np.random.choice(\n                range(len(labels)), size=nb_labels_sample, replace=False))\n            sel_layer_edge_ratios = [layer_edge_ratios[li] for li in sel_label_idxs]\n            nb_surface_pts_sel = vxm.py.utils.get_surface_pts_per_label(\n                nb_surface_pts, sel_layer_edge_ratios)\n\n        # prepare signed distance transforms and surface point arrays\n        X_sdt_k = np.zeros((batch_size, *sdt_shape, nb_labels_sample))\n        atl_dt_k = np.zeros((batch_size, *sdt_shape, nb_labels_sample))\n        subj_surface_pts = np.zeros((batch_size, nb_surface_pts, len(vol_shape) + 1))\n        if nb_labels_sample != len(labels):\n            atlas_surface_pts = np.zeros((batch_size, nb_surface_pts, len(vol_shape) + 1))\n\n        for li, sli in enumerate(sel_label_idxs):\n            # get the surface point stack indexes for this element\n            srf_idx = slice(int(np.sum(nb_surface_pts_sel[:li])), int(\n                np.sum(nb_surface_pts_sel[:li + 1])))\n\n            # get atlas surface points for this label\n            if nb_labels_sample != len(labels):\n                atlas_surface_pts_ = std_to_surf(atlas_sdt[sli], nb_surface_pts_sel[li])[\n                    np.newaxis, ...]\n                atlas_surface_pts[:, srf_idx, :-1] = np.repeat(atlas_surface_pts_, batch_size, 0)\n                atlas_surface_pts[:, srf_idx, -1] = sli\n\n            # compute X distance from surface\n            X_label = X_seg == labels[sli]\n            X_label = vxm.py.utils.clean_seg_batch(X_label, smooth_seg_std)\n            X_sdt_k[..., li] = vxm.py.utils.vol_to_sdt_batch(\n                X_label, sdt=True, sdt_vol_resize=sdt_vol_resize)[..., 0]\n\n            if surf_bidir:\n                atl_dt = atlas_sdt[li][np.newaxis, ...]\n                atl_dt_k[..., li] = np.repeat(atl_dt, batch_size, 0)\n                ssp_lst = [std_to_surf(f[...], nb_surface_pts_sel[li]) for f in X_sdt_k[..., li]]\n                subj_surface_pts[:, srf_idx, :-1] = np.stack(ssp_lst, 0)\n                subj_surface_pts[:, srf_idx, -1] = li\n\n        # check if returning segmentations instead of images\n        # this is a bit hacky for basically building a segmentation-only network (no images)\n        X_ret = X_img\n        atlas_ret = atlas_vol_bs\n\n        if align_segs:\n            assert len(labels) == 1, 'align_seg generator is only implemented for single label'\n            X_ret = X_seg == labels[0]\n            atlas_ret = atlas_seg_bs == labels[0]\n\n        # finally, output\n        if surf_bidir:\n            inputs = [X_ret, atlas_ret, X_sdt_k, atl_dt_k, subj_surface_pts, atlas_surface_pts]\n            outputs = [atlas_ret, X_ret, zero_flow, zero_surface_values, zero_surface_values]\n        else:\n            inputs = [X_ret, atlas_ret, X_sdt_k, atlas_surface_pts]\n            outputs = [atlas_ret, X_ret, zero_flow, zero_surface_values]\n\n        yield (inputs, outputs)\n</code></pre>"},{"location":"api/py/generators/#voxelmorph.py.generators.synthmorph","title":"synthmorph","text":"<pre><code>synthmorph(label_maps, batch_size=1, same_subj=False, flip=False)\n</code></pre> <p>Generator for SynthMorph registration.</p> <p>Parameters:     labels_maps: List of preloaded ND label maps without batch or feature dimension.     batch_size: Batch size.     same_subj: Return the same label map both as source and target.     flip: Randomly flip the same axes of the source and target label maps.</p> <p>Yields:     Source and target label maps as a tuple and \"true\" dummy value that SynthMorph training     will ignore, as it is unsupervised.</p> Source code in <code>voxelmorph/py/generators.py</code> <pre><code>def synthmorph(label_maps, batch_size=1, same_subj=False, flip=False):\n    \"\"\"\n    Generator for SynthMorph registration.\n\n    Parameters:\n        labels_maps: List of preloaded ND label maps without batch or feature dimension.\n        batch_size: Batch size.\n        same_subj: Return the same label map both as source and target.\n        flip: Randomly flip the same axes of the source and target label maps.\n\n    Yields:\n        Source and target label maps as a tuple and \"true\" dummy value that SynthMorph training\n        will ignore, as it is unsupervised.\n    \"\"\"\n    label_maps = np.expand_dims(label_maps, axis=-1)\n    rand = np.random.default_rng()\n\n    num_dim = label_maps.ndim - 2\n    prop = dict(replace=False, shuffle=False)\n\n    while True:\n        x = rand.choice(label_maps, size=2 * batch_size)\n        if same_subj:\n            x[batch_size:] = x[:batch_size]\n\n        if flip:\n            axes = rand.choice(num_dim, size=rand.integers(num_dim + 1), **prop)\n            x = np.flip(x, axis=axes + 1)\n\n        yield (x[:batch_size], x[batch_size:]), np.zeros(0)\n</code></pre>"},{"location":"api/py/generators/#voxelmorph.py.generators.template_creation","title":"template_creation","text":"<pre><code>template_creation(vol_names, bidir=False, batch_size=1, **kwargs)\n</code></pre> <p>Generator for unconditional template creation.</p> <p>Parameters:     vol_names: List of volume files to load, or list of preloaded volumes.     bidir: Yield input image as output for bidirectional models. Default is False.     batch_size: Batch size. Default is 1.     kwargs: Forwarded to the internal volgen generator.</p> Source code in <code>voxelmorph/py/generators.py</code> <pre><code>def template_creation(vol_names, bidir=False, batch_size=1, **kwargs):\n    \"\"\"\n    Generator for unconditional template creation.\n\n    Parameters:\n        vol_names: List of volume files to load, or list of preloaded volumes.\n        bidir: Yield input image as output for bidirectional models. Default is False.\n        batch_size: Batch size. Default is 1.\n        kwargs: Forwarded to the internal volgen generator.\n    \"\"\"\n    zeros = None\n    gen = volgen(vol_names, batch_size=batch_size, **kwargs)\n    while True:\n        scan = next(gen)[0]\n\n        # cache zeros\n        if zeros is None:\n            shape = scan.shape[1:-1]\n            zeros = np.zeros((1, *shape, len(shape)))\n\n        invols = [scan]\n        outvols = [scan, zeros, zeros, zeros] if bidir else [scan, zeros, zeros]\n        yield (invols, outvols)\n</code></pre>"},{"location":"api/py/generators/#voxelmorph.py.generators.volgen","title":"volgen","text":"<pre><code>volgen(vol_names, batch_size=1, segs=None, np_var='vol', pad_shape=None, resize_factor=1, add_feat_axis=True)\n</code></pre> <p>Base generator for random volume loading. Volumes can be passed as a path to the parent directory, a glob pattern, a list of file paths, or a list of preloaded volumes. Corresponding segmentations are additionally loaded if <code>segs</code> is provided as a list (of file paths or preloaded segmentations) or set to True. If <code>segs</code> is True, npz files with variable names 'vol' and 'seg' are expected. Passing in preloaded volumes (with optional preloaded segmentations) allows volumes preloaded in memory to be passed to a generator.</p> <p>Parameters:     vol_names: Path, glob pattern, list of volume files to load, or list of         preloaded volumes.     batch_size: Batch size. Default is 1.     segs: Loads corresponding segmentations. Default is None.     np_var: Name of the volume variable if loading npz files. Default is 'vol'.     pad_shape: Zero-pads loaded volumes to a given shape. Default is None.     resize_factor: Volume resize factor. Default is 1.     add_feat_axis: Load volume arrays with added feature axis. Default is True.</p> Source code in <code>voxelmorph/py/generators.py</code> <pre><code>def volgen(\n    vol_names,\n    batch_size=1,\n    segs=None,\n    np_var='vol',\n    pad_shape=None,\n    resize_factor=1,\n    add_feat_axis=True\n):\n    \"\"\"\n    Base generator for random volume loading. Volumes can be passed as a path to\n    the parent directory, a glob pattern, a list of file paths, or a list of\n    preloaded volumes. Corresponding segmentations are additionally loaded if\n    `segs` is provided as a list (of file paths or preloaded segmentations) or set\n    to True. If `segs` is True, npz files with variable names 'vol' and 'seg' are\n    expected. Passing in preloaded volumes (with optional preloaded segmentations)\n    allows volumes preloaded in memory to be passed to a generator.\n\n    Parameters:\n        vol_names: Path, glob pattern, list of volume files to load, or list of\n            preloaded volumes.\n        batch_size: Batch size. Default is 1.\n        segs: Loads corresponding segmentations. Default is None.\n        np_var: Name of the volume variable if loading npz files. Default is 'vol'.\n        pad_shape: Zero-pads loaded volumes to a given shape. Default is None.\n        resize_factor: Volume resize factor. Default is 1.\n        add_feat_axis: Load volume arrays with added feature axis. Default is True.\n    \"\"\"\n\n    # convert glob path to filenames\n    if isinstance(vol_names, str):\n        if os.path.isdir(vol_names):\n            vol_names = os.path.join(vol_names, '*')\n        vol_names = glob.glob(vol_names)\n\n    if isinstance(segs, list) and len(segs) != len(vol_names):\n        raise ValueError('Number of image files must match number of seg files.')\n\n    while True:\n        # generate [batchsize] random image indices\n        indices = np.random.randint(len(vol_names), size=batch_size)\n\n        # load volumes and concatenate\n        load_params = dict(np_var=np_var, add_batch_axis=True, add_feat_axis=add_feat_axis,\n                           pad_shape=pad_shape, resize_factor=resize_factor)\n        imgs = [vxm.py.utils.load_volfile(vol_names[i], **load_params) for i in indices]\n        vols = [np.concatenate(imgs, axis=0)]\n\n        # optionally load segmentations and concatenate\n        if segs is True:\n            # assume inputs are npz files with 'seg' key\n            load_params['np_var'] = 'seg'  # be sure to load seg\n            s = [vxm.py.utils.load_volfile(vol_names[i], **load_params) for i in indices]\n            vols.append(np.concatenate(s, axis=0))\n        elif isinstance(segs, list):\n            # assume segs is a corresponding list of files or preloaded volumes\n            s = [vxm.py.utils.load_volfile(segs[i], **load_params) for i in indices]\n            vols.append(np.concatenate(s, axis=0))\n\n        yield tuple(vols)\n</code></pre>"},{"location":"api/py/py/","title":"py","text":""},{"location":"api/py/py/#voxelmorph.py","title":"voxelmorph.py","text":"<p>The <code>py/</code> submodule contains non-pytorch implementations of various functions.</p>"},{"location":"api/py/utils/","title":"py.utils","text":""},{"location":"api/py/utils/#voxelmorph.py.utils","title":"voxelmorph.py.utils","text":""},{"location":"api/py/utils/#voxelmorph.py.utils.affine_shift_to_matrix","title":"affine_shift_to_matrix","text":"<pre><code>affine_shift_to_matrix(trf, resize=None, unshift_shape=None)\n</code></pre> <p>Converts an affine shift to a matrix (over the identity). To convert back from center-shifted transform, provide image shape to unshift_shape.</p> <p>TODO: make ND compatible - currently just 3D</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def affine_shift_to_matrix(trf, resize=None, unshift_shape=None):\n    \"\"\"\n    Converts an affine shift to a matrix (over the identity).\n    To convert back from center-shifted transform, provide image shape\n    to unshift_shape.\n\n    TODO: make ND compatible - currently just 3D\n    \"\"\"\n    matrix = np.concatenate([trf.reshape((3, 4)), np.zeros((1, 4))], 0) + np.eye(4)\n    if resize is not None:\n        matrix[:3, -1] *= resize\n    if unshift_shape is not None:\n        T = np.zeros((4, 4))\n        T[:3, 3] = (np.array(unshift_shape) - 1) / 2\n        matrix = (np.eye(4) + T) @ matrix @ (np.eye(4) - T)\n    return matrix\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.clean_seg","title":"clean_seg","text":"<pre><code>clean_seg(x, std=1)\n</code></pre> <p>Cleans a segmentation image.</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def clean_seg(x, std=1):\n    \"\"\"\n    Cleans a segmentation image.\n    \"\"\"\n\n    # take out islands, fill in holes, and gaussian blur\n    bw = extract_largest_vol(x)\n    bw = 1 - extract_largest_vol(1 - bw)\n    gadt = scipy.ndimage.gaussian_filter(bw.astype('float'), std)\n\n    # figure out the proper threshold to maintain the total volume\n    sgadt = np.sort(gadt.flatten())[::-1]\n    thr = sgadt[np.ceil(bw.sum()).astype(int)]\n    clean_bw = gadt &gt; thr\n\n    assert np.isclose(bw.sum(), clean_bw.sum(), atol=5), 'cleaning segmentation failed'\n    return clean_bw.astype(float)\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.clean_seg_batch","title":"clean_seg_batch","text":"<pre><code>clean_seg_batch(X_label, std=1)\n</code></pre> <p>Cleans batches of segmentation images.</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def clean_seg_batch(X_label, std=1):\n    \"\"\"\n    Cleans batches of segmentation images.\n    \"\"\"\n    if not X_label.dtype == 'float':\n        X_label = X_label.astype('float')\n\n    data = np.zeros(X_label.shape)\n    for xi, x in enumerate(X_label):\n        data[xi, ..., 0] = clean_seg(x[..., 0], std)\n\n    return data\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.dice","title":"dice","text":"<pre><code>dice(array1, array2, labels=None, include_zero=False)\n</code></pre> <p>Computes the dice overlap between two arrays for a given set of integer labels.</p> <p>Parameters:     array1: Input array 1.     array2: Input array 2.     labels: List of labels to compute dice on. If None, all labels will be used.     include_zero: Include label 0 in label list. Default is False.</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def dice(array1, array2, labels=None, include_zero=False):\n    \"\"\"\n    Computes the dice overlap between two arrays for a given set of integer labels.\n\n    Parameters:\n        array1: Input array 1.\n        array2: Input array 2.\n        labels: List of labels to compute dice on. If None, all labels will be used.\n        include_zero: Include label 0 in label list. Default is False.\n    \"\"\"\n    if labels is None:\n        labels = np.concatenate([np.unique(a) for a in [array1, array2]])\n        labels = np.sort(np.unique(labels))\n    if not include_zero:\n        labels = np.delete(labels, np.argwhere(labels == 0)) \n\n    dicem = np.zeros(len(labels))\n    for idx, label in enumerate(labels):\n        top = 2 * np.sum(np.logical_and(array1 == label, array2 == label))\n        bottom = np.sum(array1 == label) + np.sum(array2 == label)\n        bottom = np.maximum(bottom, np.finfo(float).eps)  # add epsilon\n        dicem[idx] = top / bottom\n    return dicem\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.dist_trf","title":"dist_trf","text":"<pre><code>dist_trf(bwvol)\n</code></pre> <p>Computes positive distance transform from positive entries in a logical image.</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def dist_trf(bwvol):\n    \"\"\"\n    Computes positive distance transform from positive entries in a logical image.\n    \"\"\"\n    revbwvol = np.logical_not(bwvol)\n    return scipy.ndimage.morphology.distance_transform_edt(revbwvol)\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.edge_to_surface_pts","title":"edge_to_surface_pts","text":"<pre><code>edge_to_surface_pts(X_edges, nb_surface_pts=None)\n</code></pre> <p>Converts edges to surface points.</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def edge_to_surface_pts(X_edges, nb_surface_pts=None):\n    \"\"\"\n    Converts edges to surface points.\n    \"\"\"\n\n    # assumes X_edges is NOT in keras form\n    surface_pts = np.stack(np.where(X_edges), 0).transpose()\n\n    # random with replacements\n    if nb_surface_pts is not None:\n        chi = np.random.choice(range(surface_pts.shape[0]), size=nb_surface_pts)\n        surface_pts = surface_pts[chi, :]\n\n    return surface_pts\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.extract_largest_vol","title":"extract_largest_vol","text":"<pre><code>extract_largest_vol(bw, connectivity=1)\n</code></pre> <p>Extracts the binary (boolean) image with just the largest component. TODO: This might be less than efficiently implemented.</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def extract_largest_vol(bw, connectivity=1):\n    \"\"\"\n    Extracts the binary (boolean) image with just the largest component.\n    TODO: This might be less than efficiently implemented.\n    \"\"\"\n    lab = measure.label(bw.astype('int'), connectivity=connectivity)\n    regions = measure.regionprops(lab, cache=False)\n    areas = [f.area for f in regions]\n    ai = np.argsort(areas)[::-1]\n    bw = lab == ai[0] + 1\n    return bw\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.filter_labels","title":"filter_labels","text":"<pre><code>filter_labels(atlas_vol, labels)\n</code></pre> <p>Filters given volumes to only include given labels, all other voxels are set to 0.</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def filter_labels(atlas_vol, labels):\n    \"\"\"\n    Filters given volumes to only include given labels, all other voxels are set to 0.\n    \"\"\"\n    mask = np.zeros(atlas_vol.shape, 'bool')\n    for label in labels:\n        mask = np.logical_or(mask, atlas_vol == label)\n    return atlas_vol * mask\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.get_surface_pts_per_label","title":"get_surface_pts_per_label","text":"<pre><code>get_surface_pts_per_label(total_nb_surface_pts, layer_edge_ratios)\n</code></pre> <p>Gets the number of surface points per label, given the total number of surface points.</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def get_surface_pts_per_label(total_nb_surface_pts, layer_edge_ratios):\n    \"\"\"\n    Gets the number of surface points per label, given the total number of surface points.\n    \"\"\"\n    nb_surface_pts_sel = np.round(np.array(layer_edge_ratios) * total_nb_surface_pts).astype('int')\n    nb_surface_pts_sel[-1] = total_nb_surface_pts - int(np.sum(nb_surface_pts_sel[:-1]))\n    return nb_surface_pts_sel\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.jacobian_determinant","title":"jacobian_determinant","text":"<pre><code>jacobian_determinant(disp)\n</code></pre> <p>jacobian determinant of a displacement field. NB: to compute the spatial gradients, we use np.gradient.</p> <p>Parameters:     disp: 2D or 3D displacement field of size [*vol_shape, nb_dims],            where vol_shape is of len nb_dims</p> <p>Returns:     jacobian determinant (scalar)</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def jacobian_determinant(disp):\n    \"\"\"\n    jacobian determinant of a displacement field.\n    NB: to compute the spatial gradients, we use np.gradient.\n\n    Parameters:\n        disp: 2D or 3D displacement field of size [*vol_shape, nb_dims], \n              where vol_shape is of len nb_dims\n\n    Returns:\n        jacobian determinant (scalar)\n    \"\"\"\n\n    # check inputs\n    volshape = disp.shape[:-1]\n    nb_dims = len(volshape)\n    assert len(volshape) in (2, 3), 'flow has to be 2D or 3D'\n\n    # compute grid\n    grid_lst = nd.volsize2ndgrid(volshape)\n    grid = np.stack(grid_lst, len(volshape))\n\n    # compute gradients\n    J = np.gradient(disp + grid)\n\n    # 3D glow\n    if nb_dims == 3:\n        dx = J[0]\n        dy = J[1]\n        dz = J[2]\n\n        # compute jacobian components\n        Jdet0 = dx[..., 0] * (dy[..., 1] * dz[..., 2] - dy[..., 2] * dz[..., 1])\n        Jdet1 = dx[..., 1] * (dy[..., 0] * dz[..., 2] - dy[..., 2] * dz[..., 0])\n        Jdet2 = dx[..., 2] * (dy[..., 0] * dz[..., 1] - dy[..., 1] * dz[..., 0])\n\n        return Jdet0 - Jdet1 + Jdet2\n\n    else:  # must be 2\n\n        dfdx = J[0]\n        dfdy = J[1]\n\n        return dfdx[..., 0] * dfdy[..., 1] - dfdy[..., 0] * dfdx[..., 1]\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.load_labels","title":"load_labels","text":"<pre><code>load_labels(arg, ext=('.nii.gz', '.nii', '.mgz', '.npy', '.npz'))\n</code></pre> <p>Load label maps, return a list of unique labels and the label maps. The label maps have to be of an integer type and identical shape.</p> <p>Parameters:     arg: Path to folder containing label maps, string for globbing, or a list of these.     ext: List or tuple of file extensions.</p> <p>Returns:     np.array: List of unique labels.     list: List of label maps, each as a NumPy array.</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def load_labels(arg, ext=('.nii.gz', '.nii', '.mgz', '.npy', '.npz')):\n    \"\"\"\n    Load label maps, return a list of unique labels and the label maps. The label maps have to be\n    of an integer type and identical shape.\n\n    Parameters:\n        arg: Path to folder containing label maps, string for globbing, or a list of these.\n        ext: List or tuple of file extensions.\n\n    Returns:\n        np.array: List of unique labels.\n        list: List of label maps, each as a NumPy array.\n\n    \"\"\"\n    if not isinstance(arg, (tuple, list)):\n        arg = [arg]\n\n    # List files.\n    import glob\n    files = [os.path.join(f, '*') if os.path.isdir(f) else f for f in map(str, arg)]\n    files = sum((glob.glob(f) for f in files), [])\n    files = [f for f in files if f.endswith(ext)]\n    if len(files) == 0:\n        raise ValueError(f'no labels found for argument \"{files}\"')\n\n    # Load labels.\n    label_maps = []\n    shape = None\n    for f in files:\n        x = np.squeeze(load_volfile(f))\n        if shape is None:\n            shape = np.shape(x)\n        if not np.issubdtype(x.dtype, np.integer):\n            raise ValueError(f'file \"{f}\" has non-integral data type')\n        if not np.all(x.shape == shape):\n            raise ValueError(f'shape {x.shape} of file \"{f}\" is not {shape}')\n        label_maps.append(x)\n\n    return np.unique(label_maps), label_maps\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.load_pheno_csv","title":"load_pheno_csv","text":"<pre><code>load_pheno_csv(filename, training_files=None)\n</code></pre> <p>Loads an attribute csv file into a dictionary. Each line in the csv should represent attributes for a single training file and should be formatted as:</p> <p>filename,attr1,attr2,attr2...</p> <p>Where filename is the file basename and each attr is a floating point number. If a list of training_files is specified, the dictionary file keys will be updated to match the paths specified in the list. Any training files not found in the loaded dictionary are pruned.</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def load_pheno_csv(filename, training_files=None):\n    \"\"\"\n    Loads an attribute csv file into a dictionary. Each line in the csv should represent\n    attributes for a single training file and should be formatted as:\n\n    filename,attr1,attr2,attr2...\n\n    Where filename is the file basename and each attr is a floating point number. If\n    a list of training_files is specified, the dictionary file keys will be updated\n    to match the paths specified in the list. Any training files not found in the\n    loaded dictionary are pruned.\n    \"\"\"\n\n    # load csv into dictionary\n    pheno = {}\n    with open(filename) as csv_file:\n        csv_reader = csv.reader(csv_file, delimiter=',')\n        header = next(csv_reader)\n        for row in csv_reader:\n            pheno[row[0]] = np.array([float(f) for f in row[1:]])\n\n    # make list of valid training files\n    if training_files is None:\n        training_files = list(training_files.keys())\n    else:\n        training_files = [f for f in training_files if os.path.basename(f) in pheno.keys()]\n        # make sure pheno dictionary includes the correct path to training data\n        for f in training_files:\n            pheno[f] = pheno[os.path.basename(f)]\n\n    return pheno, training_files\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.load_volfile","title":"load_volfile","text":"<pre><code>load_volfile(filename, np_var='vol', add_batch_axis=False, add_feat_axis=False, pad_shape=None, resize_factor=1, ret_affine=False)\n</code></pre> <p>Loads a file in nii, nii.gz, mgz, npz, or npy format. If input file is not a string, returns it directly (allows files preloaded in memory to be passed to a generator)</p> <p>Parameters:     filename: Filename to load, or preloaded volume to be returned.     np_var: If the file is a npz (compressed numpy) with multiple variables,         the desired variable can be specified with np_var. Default is 'vol'.     add_batch_axis: Adds an axis to the beginning of the array. Default is False.     add_feat_axis: Adds an axis to the end of the array. Default is False.     pad_shape: Zero-pad the array to a target shape. Default is None.     resize: Volume resize factor. Default is 1     ret_affine: Additionally returns the affine transform (or None if it doesn't exist).</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def load_volfile(\n    filename,\n    np_var='vol',\n    add_batch_axis=False,\n    add_feat_axis=False,\n    pad_shape=None,\n    resize_factor=1,\n    ret_affine=False\n):\n    \"\"\"\n    Loads a file in nii, nii.gz, mgz, npz, or npy format. If input file is not a string,\n    returns it directly (allows files preloaded in memory to be passed to a generator)\n\n    Parameters:\n        filename: Filename to load, or preloaded volume to be returned.\n        np_var: If the file is a npz (compressed numpy) with multiple variables,\n            the desired variable can be specified with np_var. Default is 'vol'.\n        add_batch_axis: Adds an axis to the beginning of the array. Default is False.\n        add_feat_axis: Adds an axis to the end of the array. Default is False.\n        pad_shape: Zero-pad the array to a target shape. Default is None.\n        resize: Volume resize factor. Default is 1\n        ret_affine: Additionally returns the affine transform (or None if it doesn't exist).\n    \"\"\"\n    if isinstance(filename, pathlib.PurePath):\n        filename = str(filename)\n    if isinstance(filename, str) and not os.path.isfile(filename):\n        raise ValueError(\"'%s' is not a file.\" % filename)\n\n    if not os.path.isfile(filename):\n        if ret_affine:\n            (vol, affine) = filename\n        else:\n            vol = filename\n    elif filename.endswith(('.nii', '.nii.gz', '.mgz')):\n        import nibabel as nib\n        img = nib.load(filename)\n        vol = np.squeeze(img.dataobj)\n        affine = img.affine\n    elif filename.endswith('.npy'):\n        vol = np.load(filename)\n        affine = None\n    elif filename.endswith('.npz'):\n        npz = np.load(filename)\n        vol = next(iter(npz.values())) if len(npz.keys()) == 1 else npz[np_var]\n        affine = None\n    else:\n        raise ValueError('unknown filetype for %s' % filename)\n\n    if pad_shape:\n        vol, _ = pad(vol, pad_shape)\n\n    if add_feat_axis:\n        vol = vol[..., np.newaxis]\n\n    if resize_factor != 1:\n        vol = resize(vol, resize_factor)\n\n    if add_batch_axis:\n        vol = vol[np.newaxis, ...]\n\n    return (vol, affine) if ret_affine else vol\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.pad","title":"pad","text":"<pre><code>pad(array, shape)\n</code></pre> <p>Zero-pads an array to a given shape. Returns the padded array and crop slices.</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def pad(array, shape):\n    \"\"\"\n    Zero-pads an array to a given shape. Returns the padded array and crop slices.\n    \"\"\"\n    if array.shape == tuple(shape):\n        return array, ...\n\n    padded = np.zeros(shape, dtype=array.dtype)\n    offsets = [int((p - v) / 2) for p, v in zip(shape, array.shape)]\n    slices = tuple([slice(offset, l + offset) for offset, l in zip(offsets, array.shape)])\n    padded[slices] = array\n\n    return padded, slices\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.read_file_list","title":"read_file_list","text":"<pre><code>read_file_list(filename, prefix=None, suffix=None)\n</code></pre> <p>Reads a list of files from a line-seperated text file.</p> <p>Parameters:     filename: Filename to load.     prefix: File prefix. Default is None.     suffix: File suffix. Default is None.</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def read_file_list(filename, prefix=None, suffix=None):\n    '''\n    Reads a list of files from a line-seperated text file.\n\n    Parameters:\n        filename: Filename to load.\n        prefix: File prefix. Default is None.\n        suffix: File suffix. Default is None.\n    '''\n    with open(filename, 'r') as file:\n        content = file.readlines()\n    filelist = [x.strip() for x in content if x.strip()]\n    if prefix is not None:\n        filelist = [prefix + f for f in filelist]\n    if suffix is not None:\n        filelist = [f + suffix for f in filelist]\n    return filelist\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.read_pair_list","title":"read_pair_list","text":"<pre><code>read_pair_list(filename, delim=None, prefix=None, suffix=None)\n</code></pre> <p>Reads a list of registration file pairs from a line-seperated text file.</p> <p>Parameters:     filename: Filename to load.     delim: File pair delimiter. Default is a whitespace seperator (None).     prefix: File prefix. Default is None.     suffix: File suffix. Default is None.</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def read_pair_list(filename, delim=None, prefix=None, suffix=None):\n    '''\n    Reads a list of registration file pairs from a line-seperated text file.\n\n    Parameters:\n        filename: Filename to load.\n        delim: File pair delimiter. Default is a whitespace seperator (None).\n        prefix: File prefix. Default is None.\n        suffix: File suffix. Default is None.\n    '''\n    pairlist = [f.split(delim) for f in read_file_list(filename)]\n    if prefix is not None:\n        pairlist = [[prefix + f for f in pair] for pair in pairlist]\n    if suffix is not None:\n        pairlist = [[f + suffix for f in pair] for pair in pairlist]\n    return pairlist\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.resize","title":"resize","text":"<pre><code>resize(array, factor, batch_axis=False)\n</code></pre> <p>Resizes an array by a given factor. This expects the input array to include a feature dimension. Use batch_axis=True to avoid resizing the first (batch) dimension.</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def resize(array, factor, batch_axis=False):\n    \"\"\"\n    Resizes an array by a given factor. This expects the input array to include a feature dimension.\n    Use batch_axis=True to avoid resizing the first (batch) dimension.\n    \"\"\"\n    if factor == 1:\n        return array\n    else:\n        if not batch_axis:\n            dim_factors = [factor for _ in array.shape[:-1]] + [1]\n        else:\n            dim_factors = [1] + [factor for _ in array.shape[1:-1]] + [1]\n        return scipy.ndimage.interpolation.zoom(array, dim_factors, order=0)\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.save_volfile","title":"save_volfile","text":"<pre><code>save_volfile(array, filename, affine=None)\n</code></pre> <p>Saves an array to nii, nii.gz, or npz format.</p> <p>Parameters:     array: The array to save.     filename: Filename to save to.     affine: Affine vox-to-ras matrix. Saves LIA matrix if None (default).</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def save_volfile(array, filename, affine=None):\n    \"\"\"\n    Saves an array to nii, nii.gz, or npz format.\n\n    Parameters:\n        array: The array to save.\n        filename: Filename to save to.\n        affine: Affine vox-to-ras matrix. Saves LIA matrix if None (default).\n    \"\"\"\n    if isinstance(filename, pathlib.PurePath):\n        filename = str(filename)\n\n    if filename.endswith(('.nii', '.nii.gz')):\n        import nibabel as nib\n        if affine is None and array.ndim &gt;= 3:\n            # use LIA transform as default affine\n            affine = np.array([[-1, 0, 0, 0],  # nopep8\n                               [0, 0, 1, 0],  # nopep8\n                               [0, -1, 0, 0],  # nopep8\n                               [0, 0, 0, 1]], dtype=float)  # nopep8\n            pcrs = np.append(np.array(array.shape[:3]) / 2, 1)\n            affine[:3, 3] = -np.matmul(affine, pcrs)[:3]\n        nib.save(nib.Nifti1Image(array, affine), filename)\n    elif filename.endswith('.npz'):\n        np.savez_compressed(filename, vol=array)\n    else:\n        raise ValueError('unknown filetype for %s' % filename)\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.sdt_to_surface_pts","title":"sdt_to_surface_pts","text":"<pre><code>sdt_to_surface_pts(X_sdt, nb_surface_pts, surface_pts_upsample_factor=2, thr=0.50001, resize_fn=None)\n</code></pre> <p>Converts a signed distance transform to surface points.</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def sdt_to_surface_pts(X_sdt, nb_surface_pts,\n                       surface_pts_upsample_factor=2, thr=0.50001, resize_fn=None):\n    \"\"\"\n    Converts a signed distance transform to surface points.\n    \"\"\"\n    us = [surface_pts_upsample_factor] * X_sdt.ndim\n\n    if resize_fn is None:\n        resized_vol = scipy.ndimage.interpolation.zoom(X_sdt, us, order=1, mode='reflect')\n    else:\n        resized_vol = resize_fn(X_sdt)\n        pred_shape = np.array(X_sdt.shape) * surface_pts_upsample_factor\n        assert np.array_equal(pred_shape, resized_vol.shape), 'resizing failed'\n\n    X_edges = np.abs(resized_vol) &lt; thr\n    sf_pts = edge_to_surface_pts(X_edges, nb_surface_pts=nb_surface_pts)\n\n    # can't just correct by surface_pts_upsample_factor because of how interpolation works...\n    pt = [sf_pts[..., f] * (X_sdt.shape[f] - 1) / (X_edges.shape[f] - 1) for f in range(X_sdt.ndim)]\n    return np.stack(pt, -1)\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.signed_dist_trf","title":"signed_dist_trf","text":"<pre><code>signed_dist_trf(bwvol)\n</code></pre> <p>Computes the signed distance transform from the surface between the binary elements of an image NOTE: The distance transform on either side of the surface will be +/- 1, so there are no voxels for which the distance should be 0. NOTE: Currently the function uses bwdist twice. If there is a quick way to compute the surface, bwdist could be used only once.</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def signed_dist_trf(bwvol):\n    \"\"\"\n    Computes the signed distance transform from the surface between the binary\n    elements of an image\n    NOTE: The distance transform on either side of the surface will be +/- 1,\n    so there are no voxels for which the distance should be 0.\n    NOTE: Currently the function uses bwdist twice. If there is a quick way to\n    compute the surface, bwdist could be used only once.\n    \"\"\"\n\n    # get the positive transform (outside the positive island)\n    posdst = dist_trf(bwvol)\n\n    # get the negative transform (distance inside the island)\n    notbwvol = np.logical_not(bwvol)\n    negdst = dist_trf(notbwvol)\n\n    # combine the positive and negative map\n    return posdst * notbwvol - negdst * bwvol\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.vol_to_sdt","title":"vol_to_sdt","text":"<pre><code>vol_to_sdt(X_label, sdt=True, sdt_vol_resize=1)\n</code></pre> <p>Computes the signed distance transform from a volume.</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def vol_to_sdt(X_label, sdt=True, sdt_vol_resize=1):\n    \"\"\"\n    Computes the signed distance transform from a volume.\n    \"\"\"\n\n    X_dt = signed_dist_trf(X_label)\n\n    if not (sdt_vol_resize == 1):\n        if not isinstance(sdt_vol_resize, (list, tuple)):\n            sdt_vol_resize = [sdt_vol_resize] * X_dt.ndim\n        if any([f != 1 for f in sdt_vol_resize]):\n            X_dt = scipy.ndimage.interpolation.zoom(X_dt, sdt_vol_resize, order=1, mode='reflect')\n\n    if not sdt:\n        X_dt = np.abs(X_dt)\n\n    return X_dt\n</code></pre>"},{"location":"api/py/utils/#voxelmorph.py.utils.vol_to_sdt_batch","title":"vol_to_sdt_batch","text":"<pre><code>vol_to_sdt_batch(X_label, sdt=True, sdt_vol_resize=1)\n</code></pre> <p>Computes the signed distance transforms from volume batches.</p> Source code in <code>voxelmorph/py/utils.py</code> <pre><code>def vol_to_sdt_batch(X_label, sdt=True, sdt_vol_resize=1):\n    \"\"\"\n    Computes the signed distance transforms from volume batches.\n    \"\"\"\n\n    # assume X_label is [batch_size, *vol_shape, 1]\n    assert X_label.shape[-1] == 1, 'implemented assuming size is [batch_size, *vol_shape, 1]'\n    X_lst = [f[..., 0] for f in X_label]  # get rows\n    X_dt_lst = [vol_to_sdt(f, sdt=sdt, sdt_vol_resize=sdt_vol_resize)\n                for f in X_lst]  # distance transform\n    X_dt = np.stack(X_dt_lst, 0)[..., np.newaxis]\n    return X_dt\n</code></pre>"}]}